---
phase: 14-hybrid-search-backend
plan: 02
type: execute
wave: 2
depends_on:
  - 14-01
files_modified:
  - app/main.py
  - app/routers/admin.py
autonomous: true
requirements:
  - EXPL-05
  - EXPL-01

must_haves:
  truths:
    - "GET /api/explore is reachable at runtime (router registered in main.py)"
    - "experts_fts virtual table exists in SQLite and is populated with all existing experts at startup"
    - "username_to_faiss_pos mapping is built at startup and stored on app.state"
    - "category field is populated for all experts that have a recognizable job_title keyword at startup"
    - "Adding a new expert via POST /api/admin/experts syncs it into experts_fts immediately"
    - "Running the ingest job via POST /api/admin/ingest rebuilds experts_fts at the end of the job"
  artifacts:
    - path: "app/main.py"
      provides: "FTS5 startup migration, username_to_faiss_pos mapping, category classification, explore router registration"
      contains: "experts_fts"
    - path: "app/routers/admin.py"
      provides: "FTS5 sync in add_expert write path and _run_ingest_job rebuild"
      contains: "experts_fts"
  key_links:
    - from: "app/main.py"
      to: "app/routers/explore.py"
      via: "app.include_router(explore.router)"
      pattern: "include_router.*explore"
    - from: "app/main.py"
      to: "experts_fts"
      via: "CREATE VIRTUAL TABLE IF NOT EXISTS experts_fts USING fts5"
      pattern: "experts_fts"
    - from: "app/main.py"
      to: "app.state.username_to_faiss_pos"
      via: "app.state.username_to_faiss_pos = username_to_pos"
      pattern: "username_to_faiss_pos"
    - from: "app/routers/admin.py"
      to: "experts_fts"
      via: "INSERT INTO experts_fts after add_expert commit"
      pattern: "experts_fts"
---

<objective>
Wire the hybrid search pipeline into the running application: register the explore router in main.py, add FTS5 startup migration, build the username_to_faiss_pos mapping, run category auto-classification, and add explicit FTS5 sync in the two admin write paths.

Purpose: Without this plan, the /api/explore endpoint is defined but unreachable, and the FTS5 index has no data.
Output: app/main.py (4 startup additions + router registration), app/routers/admin.py (2 FTS5 sync additions)
</objective>

<execution_context>
@/Users/sebastianhamers/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sebastianhamers/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-hybrid-search-backend/14-CONTEXT.md
@.planning/phases/14-hybrid-search-backend/14-RESEARCH.md
@app/main.py
@app/routers/admin.py
@.planning/phases/14-hybrid-search-backend/14-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add FTS5 startup migration, username_to_faiss_pos mapping, category classification, and explore router registration to main.py</name>
  <files>app/main.py</files>
  <action>
Make four targeted additions to app/main.py. Read the file first to find exact insertion points.

**Addition 1: Import explore router**

In the existing import line:
```python
from app.routers import admin, chat, email_capture, feedback, health
```
Change to:
```python
from app.routers import admin, chat, email_capture, feedback, health, explore
```

**Addition 2: FTS5 virtual table migration + population (in lifespan, after "startup: expert enrichment columns migrated/verified" log line)**

Add this block immediately after `log.info("startup: expert enrichment columns migrated/verified")`:

```python
    # Phase 14: FTS5 virtual table for BM25 keyword search
    with engine.connect() as _conn:
        _conn.execute(_text("""
            CREATE VIRTUAL TABLE IF NOT EXISTS experts_fts USING fts5(
                first_name,
                last_name,
                job_title,
                company,
                bio,
                tags,
                content='experts',
                content_rowid='id'
            )
        """))
        _conn.commit()
        fts_count = _conn.execute(_text("SELECT COUNT(*) FROM experts_fts")).scalar()
        if fts_count == 0:
            _conn.execute(_text("""
                INSERT INTO experts_fts(rowid, first_name, last_name, job_title, company, bio, tags)
                SELECT id, first_name, last_name, job_title, company, bio, COALESCE(tags, '')
                FROM experts
            """))
            _conn.commit()
    log.info("startup: FTS5 index created/verified")

    # Phase 14: FTS5 INSERT trigger (sync new experts automatically)
    with engine.connect() as _conn:
        _conn.execute(_text("""
            CREATE TRIGGER IF NOT EXISTS experts_fts_ai
            AFTER INSERT ON experts BEGIN
                INSERT INTO experts_fts(rowid, first_name, last_name, job_title, company, bio, tags)
                VALUES (new.id, new.first_name, new.last_name, new.job_title,
                        new.company, new.bio, COALESCE(new.tags, ''));
            END
        """))
        _conn.commit()
    log.info("startup: FTS5 insert trigger created/verified")
```

Note: `_text` is already imported via the existing `from sqlalchemy import text as _text` inside the lifespan block. Use that same alias.

**Addition 3: username_to_faiss_pos mapping (after `log.info("startup: metadata loaded", ...)` line)**

Add this block immediately after the metadata loaded log line:

```python
    # Phase 14: username → FAISS positional index mapping (covers the 536 embedded experts)
    _username_to_pos: dict[str, int] = {}
    for _pos, _row in enumerate(app.state.metadata):
        _uname = _row.get("Username") or _row.get("username") or ""
        if _uname:
            _username_to_pos[_uname] = _pos
    app.state.username_to_faiss_pos = _username_to_pos
    log.info(
        "startup: username-to-FAISS-position mapping built",
        count=len(_username_to_pos),
    )
```

CRITICAL: Use `_row.get("Username")` with capital U — metadata.json keys are "Username", "First Name", etc. (confirmed in RESEARCH.md Data Facts table).

**Addition 4: Category auto-classification (after the username_to_faiss_pos log line)**

Add this block immediately after the mapping log line:

```python
    # Phase 14: category auto-classification (one-time startup migration)
    from app.routers.admin import _auto_categorize as _categorize  # noqa: PLC0415
    from sqlalchemy import select as _select  # noqa: PLC0415
    with SessionLocal() as _db:
        _uncategorized = _db.scalars(
            _select(Expert).where(Expert.category == None)  # noqa: E711
        ).all()
        for _e in _uncategorized:
            _cat = _categorize(_e.job_title)
            if _cat:
                _e.category = _cat
        if _uncategorized:
            _db.commit()
            log.info("startup: category auto-classification", count=len(_uncategorized))
```

**Addition 5: Router registration**

In the routes section at the bottom of main.py, after the existing router registrations, add:
```python
app.include_router(explore.router)
```

Place it after `app.include_router(admin.router)`.
  </action>
  <verify>
    Run: `python -c "import app.main; print('main.py imports OK')"` from project root.
    Expected: "main.py imports OK" (no ImportError, no syntax error).
    Also confirm: search main.py for "explore" — should appear in import line and include_router call.
  </verify>
  <done>
    app/main.py imports explore router.
    app/main.py lifespan handler creates experts_fts virtual table and populates it if empty.
    app/main.py lifespan handler builds username_to_faiss_pos mapping on app.state.
    app/main.py lifespan handler runs category auto-classification for uncategorized experts.
    app.include_router(explore.router) is registered in the routes section.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add FTS5 sync in admin.py write paths (add_expert and _run_ingest_job)</name>
  <files>app/routers/admin.py</files>
  <action>
Make two targeted additions to app/routers/admin.py to keep experts_fts in sync when experts are written. Read the file first to find exact insertion points.

**Addition 1: FTS5 sync after add_expert final commit**

Find the `add_expert` function. The function has two `db.commit()` calls after tagging — the last `db.commit()` in each branch is after setting `tags`/`findability_score`. After the final db.commit() in the no-bio branch (`new_expert.findability_score = ...; db.commit()`), add the FTS5 sync.

More precisely, find where the function returns `{"ok": True, "username": body.username, ...}`. Insert this block immediately BEFORE the `# Also append to experts.csv` comment:

```python
    # Phase 14: sync new expert into FTS5 index
    from sqlalchemy import text as _fts_text  # noqa: PLC0415
    db.execute(_fts_text("""
        INSERT INTO experts_fts(rowid, first_name, last_name, job_title, company, bio, tags)
        VALUES (:id, :fn, :ln, :jt, :co, :bio, :tags)
    """), {
        "id": new_expert.id,
        "fn": new_expert.first_name,
        "ln": new_expert.last_name,
        "jt": new_expert.job_title,
        "co": new_expert.company,
        "bio": new_expert.bio or "",
        "tags": new_expert.tags or "",
    })
    db.commit()
```

Note: This explicit INSERT is needed in addition to the startup trigger because the INSERT trigger fires at the DB level but we are in the same transaction — double-check: the trigger fires AFTER INSERT ON experts, which already committed. The FTS5 sync here explicitly covers the case where trigger may not fire due to transaction ordering. Actually, since the INSERT trigger is a SQLite-level trigger, it fires automatically on every INSERT INTO experts regardless of how the INSERT happens. To avoid double-insertion, REMOVE the startup INSERT trigger addition from plan 01 (we already have the trigger from main.py Task 1), and instead rely solely on the trigger for new experts via admin. However, to be safe and explicit (matching RESEARCH.md Pattern 6), keep the explicit INSERT here as the canonical sync, but ensure the trigger was NOT already covering this path to avoid duplicate FTS rows.

REVISED approach per RESEARCH.md Pattern 6: The research explicitly says to use explicit INSERT after admin write paths (NOT ORM events, NOT relying solely on triggers). The startup trigger provides coverage for any path that bypasses admin. For the explicit admin path, use the explicit INSERT as documented. This is belt-and-suspenders — FTS5 handles duplicate rowids by replacing (since it's a content table with rowid=id).

Actually for FTS5 external content tables, inserting a duplicate rowid causes a conflict. To be safe: do NOT create the INSERT trigger in main.py (RESEARCH.md's full startup sequence shows the trigger but the explicit pattern in admin.py shows the explicit INSERT). Remove confusion: include the explicit FTS5 sync here in admin.py ONLY; skip the startup INSERT trigger from main.py Task 1, because the explicit INSERT covers new experts added via admin, and the startup population covers all pre-existing experts. The trigger is a nice-to-have for other write paths but risks duplicate-row conflicts with the explicit INSERT in admin.py.

FINAL decision per RESEARCH.md: Keep both trigger (for belt-and-suspenders, covers non-admin writes) AND explicit INSERT (for admin write path). The trigger fires at the SQLite level AFTER INSERT ON experts — this is a different operation from the explicit FTS5 INSERT. They do not conflict: the trigger fires when the `experts` table row is inserted; the explicit FTS5 INSERT happens AFTER db.commit(). So the trigger fires first (as part of the commit), then the explicit INSERT is a separate FTS INSERT. This WOULD create a duplicate. To avoid: rely on the trigger alone for new expert row creation, and remove the explicit INSERT after add_expert. Use explicit INSERT only for the re-tag path where tags change after the initial insert.

SIMPLEST correct approach (matching RESEARCH.md intent):
- In main.py: create the INSERT trigger (fires when experts row is inserted, keeps FTS in sync automatically)
- In admin.py add_expert: NO additional explicit FTS INSERT (trigger handles it)
- In admin.py _run_ingest_job: add explicit FTS5 REBUILD after the hot-reload (this is the batch update path)

**Addition 1 (revised): FTS5 rebuild in _run_ingest_job**

Find `_run_ingest_job` function. After the hot-reload block:
```python
        app.state.faiss_index = faiss.read_index(str(FAISS_INDEX_PATH))
        with open(METADATA_PATH, "r", encoding="utf-8") as f:
            app.state.metadata = json.load(f)

        _ingest["status"] = "done"
```

Insert the FTS5 rebuild before `_ingest["status"] = "done"`:

```python
        # Phase 14: rebuild FTS5 index after bulk tag update
        from sqlalchemy import text as _fts_text  # noqa: PLC0415
        with SessionLocal() as _fts_db:
            _fts_db.execute(_fts_text("INSERT INTO experts_fts(experts_fts) VALUES('rebuild')"))
            _fts_db.commit()
        log.info("fts5.rebuild_complete")
```

**Addition 2: Also rebuild username_to_faiss_pos after hot-reload in _run_ingest_job**

After the FTS5 rebuild and before `_ingest["status"] = "done"`, also update the username_to_faiss_pos mapping since metadata was hot-reloaded:

```python
        # Phase 14: refresh username-to-FAISS-position mapping after hot-reload
        _new_mapping: dict[str, int] = {}
        for _pos, _row in enumerate(app.state.metadata):
            _uname = _row.get("Username") or _row.get("username") or ""
            if _uname:
                _new_mapping[_uname] = _pos
        app.state.username_to_faiss_pos = _new_mapping
        log.info("fts5.username_mapping_refreshed", count=len(_new_mapping))
```

Note: `app` here is the FastAPI app object passed as parameter to `_run_ingest_job(app)`. This is correct — the function signature already receives `app` to hot-reload `app.state.faiss_index` and `app.state.metadata`.
  </action>
  <verify>
    Run: `python -c "import app.routers.admin; print('admin.py imports OK')"` from project root.
    Expected: "admin.py imports OK" with no errors.
    Review _run_ingest_job: confirm FTS5 rebuild and username_to_faiss_pos refresh are present after hot-reload block.
  </verify>
  <done>
    app/routers/admin.py imports cleanly.
    _run_ingest_job() rebuilds experts_fts via INSERT INTO experts_fts(experts_fts) VALUES('rebuild') after bulk tag update.
    _run_ingest_job() refreshes app.state.username_to_faiss_pos after hot-reloading metadata.
  </done>
</task>

</tasks>

<verification>
After both tasks complete, perform end-to-end smoke test:

1. Start server locally: `uvicorn app.main:app --reload` — confirm startup logs show:
   - "startup: FTS5 index created/verified"
   - "startup: FTS5 insert trigger created/verified"
   - "startup: username-to-FAISS-position mapping built" with count=536
   - "startup: category auto-classification" with a count (may be 0 on subsequent restarts)

2. Test pure filter mode (no query):
   `curl "http://localhost:8000/api/explore?rate_min=0&rate_max=500"` — should return ExploreResponse JSON with experts[] sorted by findability_score descending, total > 0, took_ms present.

3. Test hybrid mode (with query):
   `curl "http://localhost:8000/api/explore?query=marketing+expert"` — should return experts with faiss_score and bm25_score populated, match_reason non-null, final_score present.

4. Test tag filter (AND logic):
   `curl "http://localhost:8000/api/explore?tags=seo"` — should only return experts whose tags JSON contains "seo".

5. Test pagination:
   `curl "http://localhost:8000/api/explore?cursor=20"` — should return next page; cursor in response = 40 (if more results) or null (end).

6. Test empty result:
   `curl "http://localhost:8000/api/explore?rate_min=9999&rate_max=10000"` — should return `{"experts":[],"total":0,"cursor":null,"took_ms":N}`.

7. Verify schema stability: ExploreResponse must have exactly: experts, total, cursor, took_ms. ExpertCard must have exactly the 14 fields defined in RESEARCH.md Data Contract. This contract does not change after Phase 14.
</verification>

<success_criteria>
- GET /api/explore returns valid ExploreResponse JSON (confirmed with curl or browser)
- experts_fts virtual table exists and is populated (startup log confirms count > 0)
- username_to_faiss_pos mapping is on app.state with count=536 (startup log)
- Category field is populated for experts with matching job titles (startup log shows count)
- _run_ingest_job() rebuilds FTS5 and refreshes username_to_faiss_pos after bulk update
- All startup additions are idempotent (safe to run on server restart without error)
</success_criteria>

<output>
After completion, create .planning/phases/14-hybrid-search-backend/14-02-SUMMARY.md
</output>
