---
phase: 11-backend-settings-api
plan: "01"
type: execute
wave: 1
depends_on: []
files_modified:
  - app/models.py
  - app/main.py
  - app/services/search_intelligence.py
autonomous: true
requirements:
  - CONF-01
  - CONF-02

must_haves:
  truths:
    - "A `settings` table exists in SQLite after server startup"
    - "search_intelligence reads all 5 settings from the DB on every call, not at module import time"
    - "When no DB row exists for a key, the env var value (or hardcoded default) is used as fallback"
    - "Changing a setting in the DB is reflected in the very next chat request without restarting the server"
  artifacts:
    - path: "app/models.py"
      provides: "AppSetting ORM model with key/value columns"
      contains: "class AppSetting"
    - path: "app/main.py"
      provides: "settings table DDL migration in lifespan startup"
      contains: "settings"
    - path: "app/services/search_intelligence.py"
      provides: "get_settings(db) helper + per-call flag/threshold reading"
      contains: "get_settings"
  key_links:
    - from: "app/services/search_intelligence.py"
      to: "app/models.py AppSetting"
      via: "SQLAlchemy select query inside get_settings()"
      pattern: "select.*AppSetting"
    - from: "app/routers/chat.py"
      to: "app/services/search_intelligence.py"
      via: "retrieve_with_intelligence(db=db) — db already passed, no change needed"
      pattern: "retrieve_with_intelligence"
---

<objective>
Add the AppSetting ORM model, create the settings table at startup, and refactor search_intelligence.py to read flags and thresholds from the DB on every call instead of from module-level constants at import time.

Purpose: This is the data layer that makes all 5 intelligence settings DB-controllable without a redeploy. Plans 02 builds the admin API on top of this foundation.
Output: AppSetting model, settings table, and per-request settings reading in search_intelligence.py.
</objective>

<execution_context>
@/Users/sebastianhamers/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sebastianhamers/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@app/models.py
@app/main.py
@app/services/search_intelligence.py
@app/database.py
@app/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: AppSetting model + settings table migration</name>
  <files>app/models.py, app/main.py</files>
  <action>
In `app/models.py`, add an `AppSetting` ORM model after the `Expert` class:

```python
class AppSetting(Base):
    """
    Runtime configuration overrides for search intelligence.
    Key naming matches the env var names (SCREAMING_SNAKE_CASE) for clarity.
    When a row exists, it overrides the env var fallback.
    When no row exists for a key, search_intelligence.get_settings() falls back to the env var.
    """
    __tablename__ = "settings"

    key: Mapped[str] = mapped_column(String(100), primary_key=True, nullable=False)
    value: Mapped[str] = mapped_column(Text, nullable=False)
    updated_at: Mapped[datetime.datetime] = mapped_column(
        DateTime, default=datetime.datetime.utcnow, onupdate=datetime.datetime.utcnow, nullable=False
    )
```

The 5 valid keys are:
- `QUERY_EXPANSION_ENABLED` (bool, env fallback: `os.getenv("QUERY_EXPANSION_ENABLED", "false")`)
- `FEEDBACK_LEARNING_ENABLED` (bool, env fallback: `os.getenv("FEEDBACK_LEARNING_ENABLED", "false")`)
- `SIMILARITY_THRESHOLD` (float 0.0–1.0, env fallback: `os.getenv("SIMILARITY_THRESHOLD", "0.60")`)
- `STRONG_RESULT_MIN` (int 1–10, env fallback: `os.getenv("STRONG_RESULT_MIN", "3")`)
- `FEEDBACK_BOOST_CAP` (float 0.0–0.50 as fraction, env fallback: `os.getenv("FEEDBACK_BOOST_CAP", "0.20")`)

In `app/main.py`, add a settings table migration block inside the lifespan startup (after the existing expert enrichment columns block, before the FAISS loading). Follow the exact same idempotent ALTER TABLE try/except pattern already used for other columns. Use `CREATE TABLE IF NOT EXISTS` via raw SQL because `Base.metadata.create_all()` already runs above and will create the table on fresh DBs — but add it to ensure it is there on existing DBs too. Since `Base.metadata.create_all()` is called at the top of lifespan and the `AppSetting` model is registered with `Base`, no explicit migration DDL is needed for the settings table itself — `create_all()` will handle it. Just add a log line:

```python
log.info("startup: settings table created/verified")
```

This is the correct approach: add `AppSetting` to models.py (auto-registered with Base via the import at top of main.py), and `Base.metadata.create_all()` creates the table on fresh DBs. On existing Railway DBs, `create_all()` only creates missing tables — it does NOT drop or modify existing ones — so this is safe to deploy.
  </action>
  <verify>
Start the server locally: `uvicorn app.main:app --reload --port 8000`
Check startup logs — should include "startup: settings table created/verified" (or the standard create_all log).
Confirm settings table exists: `sqlite3 data/conversations.db ".tables"` should list `settings`.
Confirm AppSetting columns: `sqlite3 data/conversations.db "PRAGMA table_info(settings);"` shows key, value, updated_at.
  </verify>
  <done>
`settings` table exists in SQLite with columns key (TEXT PRIMARY KEY), value (TEXT), updated_at (DATETIME).
Server starts without errors.
  </done>
</task>

<task type="auto">
  <name>Task 2: Refactor search_intelligence.py to per-call DB settings</name>
  <files>app/services/search_intelligence.py</files>
  <action>
Replace the module-level flag constants in `search_intelligence.py` with a `get_settings(db: Session) -> dict` function that reads from the DB on every call, falling back to env vars when no DB row exists.

Remove the module-level constants:
```python
QUERY_EXPANSION_ENABLED: bool = _flag("QUERY_EXPANSION_ENABLED")
FEEDBACK_LEARNING_ENABLED: bool = _flag("FEEDBACK_LEARNING_ENABLED")
```
And the `STRONG_RESULT_MIN = 3` and `HYDE_TIMEOUT_SECONDS = 5.0` module-level constants (these become DB-readable too, but HYDE_TIMEOUT_SECONDS is a safety constant — keep it hardcoded at 5.0 as it is a hang-protection guard, NOT a tuneable setting).

Add a `get_settings(db: Session) -> dict` function:

```python
def get_settings(db: Session) -> dict:
    """
    Read all 5 intelligence settings from the DB, falling back to env vars.

    Called on every retrieve_with_intelligence() invocation — never cached.
    This ensures a POST /api/admin/settings change takes effect on the next request
    with no Railway redeploy required.

    Returns a dict with native Python types (bool, float, int) ready to use directly.
    """
    from app.models import AppSetting  # deferred import — avoids circular import at module load

    rows = {row.key: row.value for row in db.scalars(select(AppSetting)).all()}

    def _db_or_env(key: str, default: str) -> str:
        return rows.get(key, os.getenv(key, default))

    def _bool(key: str, default: str) -> bool:
        return _db_or_env(key, default).lower().strip() in ("true", "1", "yes")

    def _float(key: str, default: str) -> float:
        try:
            return float(_db_or_env(key, default))
        except (ValueError, TypeError):
            return float(default)

    def _int(key: str, default: str) -> int:
        try:
            return int(_db_or_env(key, default))
        except (ValueError, TypeError):
            return int(default)

    return {
        "QUERY_EXPANSION_ENABLED": _bool("QUERY_EXPANSION_ENABLED", "false"),
        "FEEDBACK_LEARNING_ENABLED": _bool("FEEDBACK_LEARNING_ENABLED", "false"),
        "SIMILARITY_THRESHOLD": _float("SIMILARITY_THRESHOLD", "0.60"),
        "STRONG_RESULT_MIN": _int("STRONG_RESULT_MIN", "3"),
        "FEEDBACK_BOOST_CAP": _float("FEEDBACK_BOOST_CAP", "0.20"),
    }
```

Update `retrieve_with_intelligence()` to call `get_settings(db)` at the top of the function and use the returned dict:

```python
def retrieve_with_intelligence(query, faiss_index, metadata, db):
    settings = get_settings(db)
    query_expansion_enabled = settings["QUERY_EXPANSION_ENABLED"]
    feedback_learning_enabled = settings["FEEDBACK_LEARNING_ENABLED"]
    strong_result_min = settings["STRONG_RESULT_MIN"]
    similarity_threshold = settings["SIMILARITY_THRESHOLD"]
    feedback_boost_cap = settings["FEEDBACK_BOOST_CAP"]
    ...
```

Replace all usages of the old module-level constants with these local variables:
- `QUERY_EXPANSION_ENABLED` → `query_expansion_enabled`
- `FEEDBACK_LEARNING_ENABLED` → `feedback_learning_enabled`
- `STRONG_RESULT_MIN` → `strong_result_min`

Update `_is_weak_query()` to accept `strong_result_min` and `similarity_threshold` as parameters (since it currently reads from module-level constants imported from retriever.py). Change its signature to:
```python
def _is_weak_query(candidates, strong_result_min: int, similarity_threshold: float) -> bool:
    strong = sum(1 for c in candidates if c.score >= similarity_threshold)
    return strong < strong_result_min
```

Update `_apply_feedback_boost()` to accept `feedback_boost_cap` as a parameter:
```python
def _apply_feedback_boost(candidates, db, feedback_boost_cap: float = 0.20) -> list:
    ...
    # Replace hardcoded 0.4 (which was 2 * 0.20 cap) with: boost_factor = feedback_boost_cap * 2
    boost_factor = feedback_boost_cap * 2  # ratio range is 0.0-1.0, cap range is 0.0-0.50
    if ratio > 0.5:
        boost = (ratio - 0.5) * boost_factor
        multipliers[url] = 1.0 + boost
    elif ratio < 0.5:
        penalty = (0.5 - ratio) * boost_factor
        multipliers[url] = 1.0 - penalty
    ...
```

Keep the `SIMILARITY_THRESHOLD` and `TOP_K` imports from `app.services.retriever` only for `_search_with_vector` (which still uses `TOP_K`). The retriever's `SIMILARITY_THRESHOLD` constant is no longer used directly — `_is_weak_query` now takes it as a parameter. Remove the `SIMILARITY_THRESHOLD` import from retriever if it is only used by `_is_weak_query`.

IMPORTANT: The module-level docstring says "flags are stable for the process lifetime" — update it to reflect that flags are now read from the DB on every request.

Do NOT use `asyncio`, threading, or caching. The DB read is a simple `SELECT *` from a small table (at most 5 rows) — acceptable overhead on every chat request.
  </action>
  <verify>
Run: `cd /Users/sebastianhamers/Documents/TCS && python -c "from app.services.search_intelligence import get_settings; print('import ok')"` — should print "import ok".
Start server: `uvicorn app.main:app --reload --port 8000`
Send a test chat request to confirm no runtime errors:
```
curl -s -N -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"email":"test@test.com","query":"I need a tax expert"}' | head -5
```
Should receive SSE events starting with `data: {"event": "status", "status": "thinking"}`.
  </verify>
  <done>
`get_settings(db)` function exists in search_intelligence.py.
`retrieve_with_intelligence()` reads settings from DB on every call.
Module-level `QUERY_EXPANSION_ENABLED` and `FEEDBACK_LEARNING_ENABLED` constants are removed.
Chat endpoint continues to work (SSE stream returns events without error).
  </done>
</task>

</tasks>

<verification>
1. `sqlite3 data/conversations.db ".tables"` lists `settings`
2. `sqlite3 data/conversations.db "PRAGMA table_info(settings);"` shows key, value, updated_at columns
3. `python -c "from app.services.search_intelligence import get_settings; print('ok')"` exits 0
4. `curl -s -N -X POST http://localhost:8000/api/chat -H "Content-Type: application/json" -d '{"email":"test@test.com","query":"I need a tax expert"}'` returns SSE events
5. Manually insert a settings row and confirm it is read: `sqlite3 data/conversations.db "INSERT INTO settings VALUES ('QUERY_EXPANSION_ENABLED','true',datetime('now'));"` then send another chat request and confirm the log shows `hyde_triggered` (if FAISS has strong experts) or that the flag was read (check structlog output)
</verification>

<success_criteria>
- AppSetting model in models.py with key (PK), value, updated_at columns
- settings table created at startup via Base.metadata.create_all()
- get_settings(db) reads all 5 keys from DB with env var fallback
- retrieve_with_intelligence() uses get_settings() per call — no module-level flag constants
- Chat endpoint works end-to-end with no regression
</success_criteria>

<output>
After completion, create `.planning/phases/11-backend-settings-api/11-01-SUMMARY.md`
</output>
