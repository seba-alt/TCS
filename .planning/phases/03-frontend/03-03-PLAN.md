---
phase: 03-frontend
plan: "03"
type: execute
wave: 3
depends_on:
  - "03-01"
  - "03-02"
files_modified:
  - frontend/src/hooks/useChat.ts
  - frontend/src/App.tsx
  - frontend/.env.local
autonomous: false
requirements:
  - CHAT-01
  - CHAT-02
  - REC-03
  - REC-04

must_haves:
  truths:
    - "User types a problem description, submits it, and sees a 'Finding experts...' spinner while the request is in flight"
    - "After the spinner, the AI narrative response appears in the chat with an animated cursor while waiting for done event"
    - "Three Expert Cards appear below the AI narrative once the stream is complete"
    - "Clicking any Expert Card opens the expert's Tinrate profile page in a new browser tab"
    - "On mobile (375px viewport), chat input is visible and accessible without horizontal scrolling, Expert Cards stack vertically"
    - "On API error, an inline error message and a Retry button appear — clicking Retry resends the same query"
    - "The conversation history scrolls — user can see all previous exchanges"
  artifacts:
    - path: "frontend/src/hooks/useChat.ts"
      provides: "SSE streaming hook — manages messages state, status, and fetch ReadableStream SSE parsing"
      exports: ["useChat"]
      min_lines: 80
    - path: "frontend/src/App.tsx"
      provides: "Root component wiring Header, ChatInput, message list, EmptyState — full chat application"
      min_lines: 60
  key_links:
    - from: "frontend/src/hooks/useChat.ts"
      to: "POST /api/chat (VITE_API_URL)"
      via: "fetch with ReadableStream body parsed as SSE"
      pattern: "VITE_API_URL.*api/chat"
    - from: "frontend/src/hooks/useChat.ts"
      to: "frontend/src/types.ts"
      via: "import { Message, ChatStatus, Expert }"
      pattern: "import.*Message.*types"
    - from: "frontend/src/App.tsx"
      to: "frontend/src/hooks/useChat.ts"
      via: "const { messages, status, sendMessage } = useChat()"
      pattern: "useChat"
    - from: "frontend/src/App.tsx"
      to: "frontend/src/components/ChatMessage.tsx"
      via: "messages.map(m => <ChatMessage message={m} />)"
      pattern: "ChatMessage"
---

<objective>
Wire all components together: build the `useChat` SSE streaming hook, compose the full App.tsx chat layout, and verify the end-to-end flow works in a browser.

Purpose: This is the integration plan — state + API + UI united into a working chatbot. The SSE hook manages the complex streaming lifecycle (thinking → streaming narrative → expert cards → done/error). App.tsx is the root that composes all components into the iMessage-style layout locked in CONTEXT.md.
Output: A fully functional React chatbot connected to the FastAPI SSE backend.
</objective>

<execution_context>
@/Users/sebastianhamers/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sebastianhamers/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-frontend/03-CONTEXT.md
@.planning/phases/03-frontend/03-01-SUMMARY.md
@.planning/phases/03-frontend/03-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build useChat SSE streaming hook and wire App.tsx</name>
  <files>
    frontend/src/hooks/useChat.ts
    frontend/src/App.tsx
    frontend/.env.local
  </files>
  <action>
    **Step 1: Create `frontend/.env.local`**

    This file is gitignored and configures the local dev API URL:
    ```
    VITE_API_URL=http://localhost:8000
    ```

    **Step 2: Create `frontend/src/hooks/useChat.ts`**

    The hook manages all SSE state. The API (POST /api/chat) does NOT use browser EventSource — it uses a POST request body, which EventSource does not support. Use `fetch` with a ReadableStream and manual SSE parsing instead.

    SSE event sequence from the backend (see app/routers/chat.py):
    1. `data: {"event": "status", "status": "thinking"}\n\n` — emitted immediately
    2. `data: {"event": "result", "type": "...", "narrative": "...", "experts": [...]}\n\n` — after generation
    3. `data: {"event": "done"}\n\n` — always last

    Error path:
    - `data: {"event": "error", "message": "..."}\n\n`
    - `data: {"event": "done"}\n\n`

    The hook must:
    - Accept `email: string` parameter (required by API for lead capture; per API schema)
    - Expose `messages: Message[]`, `status: ChatStatus`, `sendMessage(query: string): void`, `retryLast(): void`
    - On `sendMessage`: append user message → set status='thinking' → start fetch → parse SSE events
    - On `status=thinking` event: status already 'thinking', no-op
    - On `result` event: update placeholder assistant message with full narrative and experts, set isStreaming=true (cursor stays until done)
    - On `done` event: set status='done', set isStreaming=false on last assistant message
    - On `error` event: set status='error', update placeholder with error message
    - `retryLast()`: resend the last user query

    IMPORTANT — The backend sends the FULL narrative in one result event (not streamed tokens). The "typing effect" from CONTEXT.md means: display an animated cursor (isStreaming=true) while status='thinking', then reveal the full narrative when result arrives. Set isStreaming=false only on the `done` event. Do NOT attempt real token streaming — the backend does not support it.

    ```ts
    import { useState, useCallback, useRef } from 'react'
    import { Message, ChatStatus, Expert } from '../types'

    const API_URL = import.meta.env.VITE_API_URL ?? 'http://localhost:8000'

    interface UseChatOptions {
      email: string
    }

    interface UseChatReturn {
      messages: Message[]
      status: ChatStatus
      sendMessage: (query: string) => void
      retryLast: () => void
    }

    export function useChat({ email }: UseChatOptions): UseChatReturn {
      const [messages, setMessages] = useState<Message[]>([])
      const [status, setStatus] = useState<ChatStatus>('idle')
      const lastQueryRef = useRef<string>('')
      const historyRef = useRef<Array<{ role: string; content: string }>>([])

      const appendMessage = useCallback((msg: Message) => {
        setMessages((prev) => [...prev, msg])
      }, [])

      const updateLastAssistantMessage = useCallback(
        (updater: (msg: Message) => Message) => {
          setMessages((prev) => {
            const idx = [...prev].reverse().findIndex((m) => m.role === 'assistant')
            if (idx === -1) return prev
            const realIdx = prev.length - 1 - idx
            const updated = [...prev]
            updated[realIdx] = updater(updated[realIdx])
            return updated
          })
        },
        []
      )

      const sendMessage = useCallback(
        async (query: string) => {
          if (status === 'thinking' || status === 'streaming') return

          lastQueryRef.current = query

          // Append user message
          const userMsg: Message = {
            id: crypto.randomUUID(),
            role: 'user',
            content: query,
          }
          appendMessage(userMsg)

          // Add user turn to history for multi-turn context
          historyRef.current = [
            ...historyRef.current,
            { role: 'user', content: query },
          ]

          setStatus('thinking')

          // Add placeholder assistant message (shows thinking cursor)
          const thinkingMsg: Message = {
            id: crypto.randomUUID(),
            role: 'assistant',
            content: '',
            isStreaming: true,
          }
          appendMessage(thinkingMsg)

          try {
            const res = await fetch(`${API_URL}/api/chat`, {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({
                email,
                query,
                history: historyRef.current.slice(0, -1), // exclude current user turn
              }),
            })

            if (!res.ok || !res.body) {
              throw new Error(`HTTP ${res.status}`)
            }

            // Parse SSE stream manually (fetch ReadableStream, not EventSource — POST body required)
            const reader = res.body.getReader()
            const decoder = new TextDecoder()
            let buffer = ''

            while (true) {
              const { done, value } = await reader.read()
              if (done) break

              buffer += decoder.decode(value, { stream: true })

              // SSE events are separated by \n\n
              const parts = buffer.split('\n\n')
              buffer = parts.pop() ?? '' // last part may be incomplete

              for (const part of parts) {
                const dataLine = part
                  .split('\n')
                  .find((l) => l.startsWith('data: '))
                if (!dataLine) continue

                let event: Record<string, unknown>
                try {
                  event = JSON.parse(dataLine.slice(6)) // strip "data: "
                } catch {
                  continue
                }

                if (event.event === 'status' && event.status === 'thinking') {
                  // Already in thinking state — no-op
                } else if (event.event === 'result') {
                  const narrative = event.narrative as string
                  const experts = (event.experts ?? []) as Expert[]

                  setStatus('streaming')
                  updateLastAssistantMessage((msg) => ({
                    ...msg,
                    content: narrative,
                    experts: experts.length > 0 ? experts : undefined,
                    isStreaming: true, // cursor still shown until done event
                  }))

                  // Add assistant turn to history
                  historyRef.current = [
                    ...historyRef.current,
                    { role: 'assistant', content: narrative },
                  ]
                } else if (event.event === 'done') {
                  setStatus('done')
                  updateLastAssistantMessage((msg) => ({
                    ...msg,
                    isStreaming: false,
                  }))
                  // Reset to idle for next query
                  setTimeout(() => setStatus('idle'), 100)
                } else if (event.event === 'error') {
                  const errorMessage = (event.message as string) ?? 'Something went wrong.'
                  setStatus('error')
                  updateLastAssistantMessage((msg) => ({
                    ...msg,
                    content: errorMessage,
                    isStreaming: false,
                  }))
                }
              }
            }
          } catch (err) {
            setStatus('error')
            updateLastAssistantMessage((msg) => ({
              ...msg,
              content: 'Something went wrong. Please try again.',
              isStreaming: false,
            }))
          }
        },
        [status, email, appendMessage, updateLastAssistantMessage]
      )

      const retryLast = useCallback(() => {
        if (!lastQueryRef.current) return
        // Remove last assistant message (error state), keep user message
        setMessages((prev) => {
          const lastAssistantIdx = [...prev].reverse().findIndex((m) => m.role === 'assistant')
          if (lastAssistantIdx === -1) return prev
          const realIdx = prev.length - 1 - lastAssistantIdx
          return prev.slice(0, realIdx)
        })
        setStatus('idle')
        sendMessage(lastQueryRef.current)
      }, [sendMessage])

      return { messages, status, sendMessage, retryLast }
    }
    ```

    **Step 3: Rewrite `frontend/src/App.tsx`**

    CONTEXT.md layout decisions:
    - Fixed top header (Header component)
    - Scrollable message list in the middle (between header and input)
    - Fixed bottom input bar (ChatInput component)
    - Empty state when no messages
    - Email: use a placeholder email for v1 (user identity is out of scope per REQUIREMENTS.md "Out of scope: User authentication / accounts"). Use `"user@tinrate.com"` as the fixed email passed to the hook — the API requires an email for DB lead capture but user login is deferred.

    Auto-scroll to bottom after each new message using a ref on the bottom of the message list.

    ```tsx
    import { useEffect, useRef } from 'react'
    import Header from './components/Header'
    import ChatInput from './components/ChatInput'
    import ChatMessage from './components/ChatMessage'
    import EmptyState from './components/EmptyState'
    import { useChat } from './hooks/useChat'

    // v1: email is a fixed placeholder — user auth is out of scope (see REQUIREMENTS.md)
    const PLACEHOLDER_EMAIL = 'user@tinrate.com'

    export default function App() {
      const { messages, status, sendMessage, retryLast } = useChat({
        email: PLACEHOLDER_EMAIL,
      })
      const bottomRef = useRef<HTMLDivElement>(null)
      const isLoading = status === 'thinking' || status === 'streaming'

      // Auto-scroll to bottom on new messages
      useEffect(() => {
        bottomRef.current?.scrollIntoView({ behavior: 'smooth' })
      }, [messages])

      return (
        <div className="flex flex-col h-screen bg-white">
          {/* Fixed top header */}
          <Header />

          {/* Scrollable message area — padded so content clears fixed header (pt-16) and fixed input (pb-24) */}
          <main
            className="flex-1 overflow-y-auto pt-16 pb-24 px-4"
            aria-live="polite"
            aria-label="Conversation"
          >
            <div className="max-w-3xl mx-auto">
              {messages.length === 0 ? (
                <EmptyState
                  onPromptSelect={(prompt) => sendMessage(prompt)}
                />
              ) : (
                <>
                  {messages.map((message) => (
                    <ChatMessage key={message.id} message={message} />
                  ))}

                  {/* Status message during loading — shown below last user message */}
                  {isLoading && messages[messages.length - 1]?.role === 'user' && (
                    <div className="flex items-center gap-2 text-sm text-neutral-500 mb-3 pl-1">
                      <svg className="animate-spin w-4 h-4 text-brand-purple" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                        <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4" />
                        <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8v8H4z" />
                      </svg>
                      Finding experts...
                    </div>
                  )}

                  {/* Error retry button */}
                  {status === 'error' && (
                    <div className="flex justify-center mb-3">
                      <button
                        onClick={retryLast}
                        className="text-sm text-brand-purple underline hover:text-purple-700"
                      >
                        Retry
                      </button>
                    </div>
                  )}
                </>
              )}
              <div ref={bottomRef} />
            </div>
          </main>

          {/* Fixed bottom input */}
          <ChatInput onSubmit={sendMessage} disabled={isLoading} />
        </div>
      )
    }
    ```

    After writing both files, run from `frontend/`:
    `npm run build`

    Fix any TypeScript errors before proceeding.
  </action>
  <verify>
    1. `npm run build` exits 0 with no TypeScript errors
    2. `grep -n "VITE_API_URL" frontend/src/hooks/useChat.ts` returns a match
    3. `grep -n "api/chat" frontend/src/hooks/useChat.ts` returns a match
    4. `grep -n "useChat" frontend/src/App.tsx` returns a match
    5. `grep -n "retryLast\|Retry" frontend/src/App.tsx` returns a match (retry UI wired)
    6. `cat frontend/.env.local` shows VITE_API_URL=http://localhost:8000
  </verify>
  <done>
    `useChat` hook exists and exports `{ messages, status, sendMessage, retryLast }`. App.tsx composes all components. `npm run build` exits 0. `frontend/.env.local` configures local API URL.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Verify end-to-end chat flow in browser</name>
  <what-built>
    Complete React chatbot frontend:
    - Plan 01: Vite+React+TS+Tailwind scaffold with Tinrate brand colors and shared types
    - Plan 02: Header, ChatMessage, ExpertCard, ChatInput, EmptyState components
    - Plan 03: useChat SSE streaming hook + App.tsx integration

    The app connects to the FastAPI backend (POST /api/chat SSE endpoint) running locally.
  </what-built>
  <how-to-verify>
    **Prerequisites:** FastAPI backend must be running.

    Start the backend (from project root):
    ```
    uvicorn app.main:app --reload
    ```

    Start the frontend (from `frontend/`):
    ```
    npm run dev
    ```

    Open http://localhost:5173 in a browser.

    **Verification checklist:**

    1. DESKTOP (any width >= 768px):
       - [ ] Tinrate header is visible at top (logo area + tagline)
       - [ ] Empty state shows welcome message and 3 example prompt buttons
       - [ ] Clicking an example prompt sends it immediately
       - [ ] Spinner + "Finding experts..." appears while waiting
       - [ ] AI narrative response appears in the chat
       - [ ] 3 Expert Cards appear below the narrative, each showing name, title, company, hourly rate
       - [ ] Clicking an Expert Card opens the expert's Tinrate profile in a new tab
       - [ ] Input bar is fixed at the bottom and always visible

    2. MOBILE (resize browser to 375px wide, or use DevTools mobile emulator):
       - [ ] All content fits within 375px width — no horizontal scrollbar
       - [ ] Chat input is accessible at the bottom without scrolling horizontally
       - [ ] Expert Cards stack vertically (one per row)
       - [ ] Send button is large enough to tap (48x48px minimum)

    3. ERROR STATE:
       - [ ] Stop the backend (Ctrl+C), send a message — error message appears in chat
       - [ ] "Retry" button appears below the error — clicking it resends the query
       - [ ] Restart backend, click Retry — chat resumes normally

    4. MULTI-TURN:
       - [ ] Send a second message after first response — conversation history is visible
       - [ ] Previous messages scroll above the new exchange

    Type "approved" if all checks pass, or describe any issues found.
  </how-to-verify>
  <resume-signal>Type "approved" to continue, or describe issues to fix</resume-signal>
  <action>Start the FastAPI backend with `uvicorn app.main:app --reload` from the project root. Start the frontend with `npm run dev` from the `frontend/` directory. Open http://localhost:5173 and test the full chat flow per the checklist in how-to-verify above.</action>
  <verify>Human confirms all checklist items pass: desktop chat flow, mobile layout at 375px, error state with Retry, multi-turn history.</verify>
  <done>Human types "approved" — all Phase 3 success criteria met: chat input works, 3 Expert Cards appear with clickable profile links, mobile layout is correct, error and retry work.</done>
</task>

</tasks>

<verification>
End-to-end flow verified by human:
1. User submits a problem description → spinner appears → AI narrative streams in → 3 Expert Cards appear
2. Each Expert Card click opens profile URL in new tab
3. Mobile 375px viewport: no horizontal scroll, cards stack vertically, input accessible
4. Error state: inline error + Retry button resends query
5. `npm run build` exits 0 with no TypeScript errors
</verification>

<success_criteria>
- `npm run build` exits 0 with no TypeScript errors
- Human verifies full chat flow: input → spinner → narrative → 3 Expert Cards → clickable links
- Human verifies mobile layout at 375px: no horizontal scroll, vertical card stacking
- Human verifies error state: error message + Retry button appear and function
- Human verifies multi-turn: conversation history visible and scrollable
</success_criteria>

<output>
After completion, create `.planning/phases/03-frontend/03-03-SUMMARY.md` following the summary template.
</output>
