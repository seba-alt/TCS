---
phase: 08-test-lab-run-queries-against-search-engine-evaluate-results-iterate-on-retrieval-quality
plan: "01"
type: execute
wave: 1
depends_on: []
files_modified:
  - app/models.py
  - app/main.py
  - app/services/tagging.py
autonomous: true
requirements:
  - TAGS-02
  - FIND-01
  - FIND-02

must_haves:
  truths:
    - "Expert table has tags Text column (nullable) and findability_score Float column (nullable) in SQLite after server startup"
    - "Experts with no bio score below 40 when compute_findability_score() is called (0 pts bio + 0 pts tags = max 35 pts from other fields)"
    - "compute_findability_score() is importable from app.services.tagging and callable from both the batch script and admin endpoint without circular imports"
  artifacts:
    - path: "app/models.py"
      provides: "Expert model with tags Text and findability_score Float columns"
      contains: "tags.*Mapped.*Text|findability_score.*Mapped.*Float"
    - path: "app/main.py"
      provides: "Idempotent ALTER TABLE migrations for tags and findability_score columns"
      contains: "ALTER TABLE experts ADD COLUMN tags TEXT"
    - path: "app/services/tagging.py"
      provides: "compute_findability_score() and _tag_expert_sync() shared functions"
      exports:
        - compute_findability_score
        - tag_expert_sync
  key_links:
    - from: "app/services/tagging.py"
      to: "app/models.py"
      via: "imports Expert model for type hints"
      pattern: "from app.models import Expert"
    - from: "app/main.py"
      to: "SQLite experts table"
      via: "ALTER TABLE DDL in lifespan"
      pattern: "ALTER TABLE experts ADD COLUMN"
---

<objective>
Add tags and findability_score columns to the Expert model and SQLite DB, and extract shared tagging logic into a reusable service module.

Purpose: All Phase 8 work (batch script, ingest rewrite, auto-tag on create) requires the schema columns to exist and the scoring/tagging functions to be importable from a shared location. This plan establishes that foundation.

Output: Expert model updated, idempotent migrations in lifespan, app/services/tagging.py with compute_findability_score() and tag_expert_sync().
</objective>

<execution_context>
@/Users/sebastianhamers/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sebastianhamers/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-test-lab-run-queries-against-search-engine-evaluate-results-iterate-on-retrieval-quality/08-CONTEXT.md
@.planning/phases/08-test-lab-run-queries-against-search-engine-evaluate-results-iterate-on-retrieval-quality/08-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend Expert model and add idempotent DB migrations</name>
  <files>app/models.py, app/main.py</files>
  <action>
In app/models.py, add two new columns to the Expert class after the existing `category` column:

```python
tags: Mapped[str | None] = mapped_column(Text, nullable=True)
findability_score: Mapped[float | None] = mapped_column(Float, nullable=True)
```

Text is already imported (used for Conversation.query). Float is already imported (used for Conversation.top_match_score). No new imports needed.

In app/main.py, add two more DDL strings to the existing migration loop in the lifespan (lines ~116–124). The loop currently migrates conversations columns; add an equivalent block for the experts table immediately after the existing block:

```python
# Phase 8: expert enrichment columns
with engine.connect() as _conn:
    for _col_ddl in [
        "ALTER TABLE experts ADD COLUMN tags TEXT",
        "ALTER TABLE experts ADD COLUMN findability_score REAL",
    ]:
        try:
            _conn.execute(_text(_col_ddl))
            _conn.commit()
        except Exception:
            pass  # Column already exists — idempotent
log.info("startup: expert enrichment columns migrated/verified")
```

Use the IDENTICAL pattern to the existing migrations block — same import (`from sqlalchemy import text as _text` is already imported in the lifespan). Do NOT use Alembic. Do NOT add a new import for `_text` — it is already there in the lifespan.
  </action>
  <verify>
Run: python -c "from app.models import Expert; print(hasattr(Expert, 'tags'), hasattr(Expert, 'findability_score'))"
Expected output: True True

Run: python -c "from app.main import app" — should import without errors.
  </verify>
  <done>Expert.tags and Expert.findability_score attributes exist on the model class. main.py imports without error. The migration block is idempotent (running twice doesn't raise).</done>
</task>

<task type="auto">
  <name>Task 2: Create app/services/tagging.py with compute_findability_score and tag_expert_sync</name>
  <files>app/services/tagging.py</files>
  <action>
Create a new file app/services/tagging.py. This module provides two exportable functions:

**compute_findability_score(expert, tags=None) -> float**

Deterministic formula from FIND-01. No LLM call. Accepts an Expert ORM instance and optional tags list (if provided, uses it instead of reading expert.tags from DB — needed during batch processing where tags were just computed but not yet committed):

```python
import json
from app.models import Expert

def compute_findability_score(expert: "Expert", tags: list[str] | None = None) -> float:
    """
    Compute 0-100 findability score per FIND-01 formula:
      Bio presence/length : 40 pts (linear scale, 500 chars = max)
      Tags present        : 25 pts
      Profile URL present : 15 pts
      Job title present   : 10 pts
      Hourly rate > 0     : 10 pts
    """
    score = 0.0

    bio = (expert.bio or "").strip()
    if bio:
        score += min(40.0, len(bio) / 500 * 40)

    effective_tags = tags if tags is not None else json.loads(expert.tags or "[]")
    if effective_tags:
        score += 25.0

    if (expert.profile_url or "").strip():
        score += 15.0

    if (expert.job_title or "").strip():
        score += 10.0

    if expert.hourly_rate and expert.hourly_rate > 0:
        score += 10.0

    return round(score, 1)
```

**tag_expert_sync(expert) -> list[str]**

Synchronous Gemini call using the SYNC client (not `client.aio`) — this is critical because the admin endpoint is a sync FastAPI route (def, not async def) and calling asyncio.run() inside an already-running event loop raises RuntimeError. The sync client.models.generate_content is correct here.

```python
import json
import os
from google import genai
from google.genai import types
from pydantic import BaseModel
from typing import List

class ExpertTags(BaseModel):
    tags: List[str]

def tag_expert_sync(expert: "Expert") -> list[str]:
    """
    Call Gemini 2.5 Flash synchronously to generate domain tags for one expert.
    Returns normalized (lowercase, stripped) tag list.
    Raises on API failure — caller is responsible for try/except.
    Uses sync client — safe to call from sync FastAPI routes.
    """
    client = genai.Client()
    prompt = (
        f"Generate 3-8 concise domain expertise tags for this professional consultant.\n\n"
        f"Name: {expert.username}\n"
        f"Job Title: {expert.job_title or 'N/A'}\n"
        f"Bio: {expert.bio}\n\n"
        f"Example tags: 'machine learning', 'tax law', 'veterinary', 'crypto', "
        f"'real estate', 'supply chain', 'fundraising', 'climate tech'\n\n"
        f"Return tags that reflect their actual domain — not generic business terms."
    )
    response = client.models.generate_content(
        model="gemini-2.5-flash",
        contents=prompt,
        config=types.GenerateContentConfig(
            response_mime_type="application/json",
            response_schema=ExpertTags,
            temperature=0.2,
        ),
    )
    data = ExpertTags.model_validate_json(response.text)
    return [t.lower().strip() for t in data.tags if t.strip()]
```

Add module-level docstring:
```
"""
Shared expert enrichment utilities: tag generation and findability scoring.

Used by:
  - scripts/tag_experts.py  (batch run; async variant calls Gemini async)
  - app/routers/admin.py    (sync call on POST /api/admin/experts)

tag_expert_sync() uses the sync google-genai client — ONLY call from sync
FastAPI route handlers. For async batch context, use the async pattern in
scripts/tag_experts.py directly.
"""
```

Do NOT instantiate the genai.Client at module load time. Instantiate inside tag_expert_sync() on each call — this avoids issues when the module is imported in the batch script context where environment may not yet be loaded.
  </action>
  <verify>
Run: python -c "from app.services.tagging import compute_findability_score, tag_expert_sync; print('ok')"
Expected: ok (no ImportError)

Run: python -c "
from app.services.tagging import compute_findability_score
from app.models import Expert
e = Expert(bio='', job_title='', profile_url='', hourly_rate=0.0)
print(compute_findability_score(e))  # Should be 0.0
e2 = Expert(bio='x' * 100, job_title='Developer', profile_url='https://tinrate.com/u/test', hourly_rate=150.0)
print(compute_findability_score(e2, tags=['python']))  # Should be > 40
"
  </verify>
  <done>compute_findability_score returns 0.0 for an empty expert, returns a positive score for an expert with bio/tags/profile/title/rate. tag_expert_sync is importable. No circular imports.</done>
</task>

</tasks>

<verification>
1. python -c "from app.models import Expert; e = Expert(); print(e.tags, e.findability_score)" — prints "None None"
2. python -c "from app.services.tagging import compute_findability_score, tag_expert_sync" — no ImportError
3. python -c "from app.main import app" — no import errors
4. The migration DDL is idempotent: running the lifespan block twice on a DB that already has the columns should not raise.
</verification>

<success_criteria>
- Expert.tags (Text, nullable) and Expert.findability_score (Float, nullable) exist in ORM model
- app/main.py lifespan runs ALTER TABLE for both columns with try/except (idempotent)
- app/services/tagging.py exports compute_findability_score() and tag_expert_sync()
- compute_findability_score() returns < 40 for expert with no bio and no profile URL (FIND-01 validation)
- No circular imports
</success_criteria>

<output>
After completion, create `.planning/phases/08-test-lab-run-queries-against-search-engine-evaluate-results-iterate-on-retrieval-quality/08-01-SUMMARY.md`
</output>
