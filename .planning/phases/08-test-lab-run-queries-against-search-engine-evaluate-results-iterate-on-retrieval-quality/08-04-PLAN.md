---
phase: 08-test-lab-run-queries-against-search-engine-evaluate-results-iterate-on-retrieval-quality
plan: "04"
type: execute
wave: 2
depends_on:
  - "08-01"
files_modified:
  - app/routers/admin.py
  - frontend/src/admin/ExpertTab.tsx
autonomous: true
requirements:
  - TAGS-05

must_haves:
  truths:
    - "When admin submits a new expert with a non-empty bio via POST /api/admin/experts, the API synchronously calls Gemini, stores tags and findability_score on the expert, and returns {ok, username, tags, findability_score} — the expert is fully enriched before the response arrives"
    - "If Gemini fails during the synchronous call, the expert is saved with tags=null and a BackgroundTasks retry is scheduled — expert creation never fails due to a Gemini error"
    - "When an admin submits a new expert with no bio, no Gemini call is made; a findability_score is still computed and returned"
    - "The admin UI shows a 'Generating tags...' message (not just a generic spinner) while the create-expert form is submitting"
  artifacts:
    - path: "app/routers/admin.py"
      provides: "POST /api/admin/experts with synchronous tagging + BackgroundTasks retry"
      contains: "BackgroundTasks|background_tasks"
    - path: "frontend/src/admin/ExpertTab.tsx"
      provides: "Admin expert creation form with 'Generating tags...' status message"
      contains: "Generating tags"
  key_links:
    - from: "app/routers/admin.py"
      to: "app/services/tagging.py"
      via: "imports tag_expert_sync and compute_findability_score"
      pattern: "from app.services.tagging import"
    - from: "app/routers/admin.py"
      to: "fastapi BackgroundTasks"
      via: "background retry on Gemini failure"
      pattern: "BackgroundTasks"
---

<objective>
Extend POST /api/admin/experts to automatically generate domain tags and a findability score for every new expert synchronously (with BackgroundTasks fallback retry on failure), and update the admin UI to show a clear "Generating tags..." status message during submission.

Purpose: TAGS-05 requires that new experts added via the dashboard are immediately enriched — no manual batch run needed. Admins should understand the ~1-2s wait is AI tagging, not just a save operation.

Output: Updated app/routers/admin.py endpoint and updated frontend/src/admin/ExpertTab.tsx submission state message.
</objective>

<execution_context>
@/Users/sebastianhamers/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sebastianhamers/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-test-lab-run-queries-against-search-engine-evaluate-results-iterate-on-retrieval-quality/08-CONTEXT.md
@.planning/phases/08-test-lab-run-queries-against-search-engine-evaluate-results-iterate-on-retrieval-quality/08-RESEARCH.md
@.planning/phases/08-test-lab-run-queries-against-search-engine-evaluate-results-iterate-on-retrieval-quality/08-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend POST /api/admin/experts with synchronous auto-tagging and BackgroundTasks retry</name>
  <files>app/routers/admin.py</files>
  <action>
Modify app/routers/admin.py to add auto-tagging to the add_expert endpoint. Make the following changes:

**1. Add new imports at the top of the file:**

Add to the existing fastapi imports line:
```python
from fastapi import APIRouter, BackgroundTasks, Depends, HTTPException, Security, status
```
(BackgroundTasks added alongside the existing imports)

Add import for tagging service after the existing local imports:
```python
import json
from app.services.tagging import compute_findability_score, tag_expert_sync
```
Note: `json` may already be imported — only add if not present.

Add structlog logger if not already present:
```python
import structlog
log = structlog.get_logger()
```
(Already present in the file — do not add duplicate)

**2. Add background retry helper function** before the add_expert endpoint definition:

```python
def _retry_tag_expert_background(expert_id: int) -> None:
    """
    Background retry for auto-tagging when synchronous Gemini call fails.
    Called by BackgroundTasks — runs after response is sent.
    Uses sync tagging (tag_expert_sync) which uses the sync google-genai client.
    """
    from app.database import SessionLocal  # noqa: PLC0415 — local import avoids circular at module load

    try:
        with SessionLocal() as db:
            from sqlalchemy import select  # noqa: PLC0415
            from app.models import Expert  # noqa: PLC0415
            expert = db.scalar(select(Expert).where(Expert.id == expert_id))
            if not expert or not (expert.bio or "").strip():
                return  # No bio — skip tagging, findability already computed
            tags = tag_expert_sync(expert)
            score = compute_findability_score(expert, tags)
            expert.tags = json.dumps(tags)
            expert.findability_score = score
            db.commit()
    except Exception as e:
        log.error("background_tag_retry.failed", expert_id=expert_id, error=str(e))
```

**3. Replace the add_expert endpoint signature and body:**

Change the function signature to accept BackgroundTasks:
```python
@router.post("/experts")
def add_expert(body: AddExpertBody, background_tasks: BackgroundTasks, db: Session = Depends(get_db)):
```

Keep all existing expert creation logic (username duplicate check, profile_url construction, Expert(...) creation, db.add, db.commit, db.refresh, csv append logic).

After `db.refresh(new_expert)` and before the CSV append block, add the auto-tagging logic:

```python
    # Auto-tag: synchronous Gemini call if expert has a bio
    if (new_expert.bio or "").strip():
        try:
            tags = tag_expert_sync(new_expert)
            score = compute_findability_score(new_expert, tags)
            new_expert.tags = json.dumps(tags)
            new_expert.findability_score = score
            db.commit()
        except Exception as e:
            log.warning(
                "add_expert.tagging_failed_scheduling_retry",
                username=body.username,
                error=str(e),
            )
            # Save expert with tags=null; schedule background retry
            background_tasks.add_task(_retry_tag_expert_background, new_expert.id)
    else:
        # No bio — compute findability score only (0 pts for bio + tags components)
        new_expert.findability_score = compute_findability_score(new_expert, tags=None)
        db.commit()
```

**4. Update the return value** to include tags and findability_score:

```python
    return {
        "ok": True,
        "username": body.username,
        "tags": json.loads(new_expert.tags or "null"),
        "findability_score": new_expert.findability_score,
    }
```

Keep the existing CSV append logic unchanged — it still appends to experts.csv for historical compatibility. The CSV append block should remain between the auto-tagging block and the return statement.

IMPORTANT pitfall to avoid: tag_expert_sync uses the sync google-genai client (`client.models.generate_content`). This is correct for a sync FastAPI route handler (def, not async def). Do NOT use asyncio.run() here — it raises RuntimeError in an already-running event loop. The sync client is defined in app/services/tagging.py (Plan 01).
  </action>
  <verify>
Run: python -c "from app.routers.admin import add_expert, _retry_tag_expert_background; print('ok')"
Expected: ok

Run: python -c "
import inspect
from app.routers.admin import add_expert
sig = inspect.signature(add_expert)
print('background_tasks param:', 'background_tasks' in sig.parameters)
"
Expected: background_tasks param: True

Run: python -c "from app.main import app; print('app imports ok')"
Expected: app imports ok
  </verify>
  <done>add_expert endpoint accepts BackgroundTasks, calls tag_expert_sync synchronously for experts with bio, falls back to background retry on Gemini failure, computes findability score for no-bio experts, returns tags and findability_score in response.</done>
</task>

<task type="auto">
  <name>Task 2: Update admin UI to show "Generating tags..." during expert creation</name>
  <files>frontend/src/admin/ExpertTab.tsx</files>
  <action>
Read frontend/src/admin/ExpertTab.tsx first to understand the current form submit / loading state implementation.

Find the submit button or loading state in the expert creation form. The current implementation likely shows a generic loading state ("Saving..." or a spinner) when the form is submitted.

Change the loading message during expert creation to "Generating tags..." so admins understand the wait is due to AI tagging.

Specific changes:
1. If there is a boolean `isSubmitting` / `loading` / `saving` state: change the button text from whatever it currently says (e.g., "Adding..." or "Saving...") to "Generating tags..." during submission.
2. If the button shows a spinner without text: add the text "Generating tags..." alongside the spinner.
3. The change is only to the in-progress text label — do not change the idle state button text (e.g., "Add Expert" stays as-is), do not change any form fields, do not change any other behavior.

Look for the submit button rendering and the condition that shows the loading/disabled state. The pattern is typically:
```tsx
<button disabled={isSubmitting}>
  {isSubmitting ? "Saving..." : "Add Expert"}
</button>
```

Change to:
```tsx
<button disabled={isSubmitting}>
  {isSubmitting ? "Generating tags..." : "Add Expert"}
</button>
```

If the component uses a different loading state variable or button pattern, adapt accordingly — the key requirement from CONTEXT.md is that the button/status text says "Generating tags..." (not just a spinner) while the submission is in flight.

Do NOT change any other behavior: form validation, success/error handling, the fields accepted, or any other UI element.
  </action>
  <verify>
Run: grep -r "Generating tags" frontend/src/admin/ExpertTab.tsx
Expected: at least one match showing "Generating tags..."

Run: cd frontend && npm run build 2>&1 | tail -5 (or equivalent TypeScript check)
Expected: no TypeScript compilation errors related to ExpertTab.tsx
  </verify>
  <done>"Generating tags..." text appears in ExpertTab.tsx submit button loading state. No TypeScript errors in the file.</done>
</task>

</tasks>

<verification>
1. python -c "from app.routers.admin import add_expert, _retry_tag_expert_background" → no ImportError
2. python -c "from app.main import app" → no ImportError
3. grep "BackgroundTasks\|background_tasks" app/routers/admin.py → both present
4. grep "tag_expert_sync\|compute_findability_score" app/routers/admin.py → both present
5. grep "Generating tags" frontend/src/admin/ExpertTab.tsx → present
6. grep "findability_score" app/routers/admin.py → present in return statement
</verification>

<success_criteria>
- POST /api/admin/experts calls tag_expert_sync() synchronously when expert has a bio
- On Gemini failure: expert saved with tags=null, BackgroundTasks schedules _retry_tag_expert_background
- Expert with no bio: findability_score computed (no Gemini call), tags=null
- Response includes tags and findability_score fields
- ExpertTab.tsx shows "Generating tags..." text during form submission
- No circular imports, no asyncio.run() in the sync route handler
</success_criteria>

<output>
After completion, create `.planning/phases/08-test-lab-run-queries-against-search-engine-evaluate-results-iterate-on-retrieval-quality/08-04-SUMMARY.md`
</output>
