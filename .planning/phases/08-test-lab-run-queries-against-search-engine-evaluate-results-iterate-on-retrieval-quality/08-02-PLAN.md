---
phase: 08-test-lab-run-queries-against-search-engine-evaluate-results-iterate-on-retrieval-quality
plan: "02"
type: execute
wave: 2
depends_on:
  - "08-01"
files_modified:
  - scripts/tag_experts.py
  - requirements.txt
autonomous: true
requirements:
  - TAGS-01
  - FIND-03

must_haves:
  truths:
    - "Running scripts/tag_experts.py processes all experts with a non-empty bio, writes tags and findability scores to SQLite, and shows a tqdm progress bar (e.g., 423/1558)"
    - "Experts with no bio are skipped entirely (no Gemini call) but still receive a findability score computed with 0 pts for bio and tags"
    - "A second run of the script skips experts where tags IS NOT NULL and produces no errors"
    - "If an individual expert's Gemini call fails, the script retries once then logs a skip — it does not abort the entire run"
    - "A run summary is printed only if there were failures or skips; clean runs exit silently after the progress bar completes"
  artifacts:
    - path: "scripts/tag_experts.py"
      provides: "Async batch tagging and findability scoring script"
      min_lines: 80
    - path: "requirements.txt"
      provides: "tqdm dependency added"
      contains: "tqdm"
  key_links:
    - from: "scripts/tag_experts.py"
      to: "app/services/tagging.py"
      via: "imports compute_findability_score"
      pattern: "from app.services.tagging import compute_findability_score"
    - from: "scripts/tag_experts.py"
      to: "app/database.py"
      via: "imports SessionLocal for DB reads/writes"
      pattern: "from app.database import SessionLocal"
    - from: "scripts/tag_experts.py"
      to: "SQLite experts table"
      via: "writes tags and findability_score per expert"
      pattern: "expert\\.tags\\s*=|expert\\.findability_score\\s*="
---

<objective>
Create scripts/tag_experts.py — an async batch script that AI-tags all experts using Gemini 2.5 Flash structured output, computes findability scores for all experts (including untagged), and writes results to SQLite.

Purpose: This is the core data enrichment step. After running this script, every Expert row has a findability score, and every expert with a bio has AI-generated domain tags stored as a JSON text column.

Output: scripts/tag_experts.py executable offline script, tqdm added to requirements.txt.
</objective>

<execution_context>
@/Users/sebastianhamers/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sebastianhamers/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-test-lab-run-queries-against-search-engine-evaluate-results-iterate-on-retrieval-quality/08-CONTEXT.md
@.planning/phases/08-test-lab-run-queries-against-search-engine-evaluate-results-iterate-on-retrieval-quality/08-RESEARCH.md
@.planning/phases/08-test-lab-run-queries-against-search-engine-evaluate-results-iterate-on-retrieval-quality/08-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add tqdm to requirements.txt</name>
  <files>requirements.txt</files>
  <action>
Add tqdm to requirements.txt immediately after the existing production dependencies, before the dev/testing section:

```
tqdm==4.66.*
```

Place it after the `structlog` and `sqlalchemy` lines, before the blank line separating production from dev dependencies. No other changes to requirements.txt.
  </action>
  <verify>
Run: grep "tqdm" requirements.txt
Expected: tqdm==4.66.*
  </verify>
  <done>tqdm==4.66.* appears in requirements.txt</done>
</task>

<task type="auto">
  <name>Task 2: Create scripts/tag_experts.py — async batch tagging with concurrency control</name>
  <files>scripts/tag_experts.py</files>
  <action>
Create scripts/tag_experts.py. Full structure below — follow exactly.

```python
#!/usr/bin/env python3
"""
Offline batch script: AI-tag all experts using Gemini 2.5 Flash structured output.

Usage:
  python scripts/tag_experts.py

Prerequisites:
  1. GOOGLE_API_KEY set in environment (or .env file)
  2. scripts/tag_experts.py run AFTER scripts/ingest.py has populated the Expert DB table
  3. Run from repo root: python scripts/tag_experts.py

Behavior:
  - Skips experts where tags IS NOT NULL (idempotent — safe to re-run)
  - Skips experts with no bio — marks them in the skip log (no Gemini call)
  - On Gemini failure: retry once, then skip and log (does not abort the run)
  - After tagging run: computes findability scores for ALL experts (including no-bio ones)
  - Shows tqdm progress bar: "Tagging 423/1558"
  - Prints run summary only if failures/skips occurred

CONCURRENCY: default 5 concurrent Gemini calls. Tune upward after checking your
Gemini paid-tier RPM limit at https://ai.google.dev/gemini-api/docs/rate-limits
(Tier 1 is approximately 150 RPM for gemini-2.5-flash).
"""
import asyncio
import json
import sys
from pathlib import Path
from typing import List

from dotenv import load_dotenv
from google import genai
from google.genai import types
from pydantic import BaseModel
from tqdm.asyncio import tqdm as async_tqdm

# Load .env for local development — no-op in production
load_dotenv()

# Allow importing from app/ when run from repo root
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

from app.database import SessionLocal  # noqa: E402
from app.models import Expert  # noqa: E402
from app.services.tagging import compute_findability_score  # noqa: E402
from sqlalchemy import select  # noqa: E402

# ── Config ─────────────────────────────────────────────────────────────────────

CONCURRENCY = 5  # Concurrent Gemini calls. Tune after checking AI Studio RPM limit.
MODEL = "gemini-2.5-flash"


# ── Pydantic schema for structured output ──────────────────────────────────────

class ExpertTags(BaseModel):
    tags: List[str]


# ── DB helpers ─────────────────────────────────────────────────────────────────

def _load_untagged_experts() -> list[Expert]:
    """Load all Expert rows where tags IS NULL (not yet tagged)."""
    with SessionLocal() as db:
        return list(db.scalars(
            select(Expert).where(Expert.tags.is_(None))
        ).all())


def _load_all_experts() -> list[Expert]:
    """Load all Expert rows for findability score computation."""
    with SessionLocal() as db:
        return list(db.scalars(select(Expert)).all())


def _write_tags_to_db(expert_id: int, tags: list[str], score: float) -> None:
    """Write tags and findability score for one expert. Opens a fresh session."""
    with SessionLocal() as db:
        expert = db.get(Expert, expert_id)
        if expert:
            expert.tags = json.dumps(tags)
            expert.findability_score = score
            db.commit()


def _write_score_to_db(expert_id: int, score: float) -> None:
    """Write findability score only (for no-bio experts that were skipped)."""
    with SessionLocal() as db:
        expert = db.get(Expert, expert_id)
        if expert:
            expert.findability_score = score
            db.commit()


# ── Gemini async call ──────────────────────────────────────────────────────────

async def _call_gemini_for_tags(client: genai.Client, expert: Expert) -> list[str]:
    """
    Async Gemini call returning normalized domain tags.
    Uses client.aio (async variant) — correct for asyncio context.
    NEVER call this from a sync FastAPI route handler.
    """
    prompt = (
        f"Generate 3-8 concise domain expertise tags for this professional consultant.\n\n"
        f"Name: {expert.username}\n"
        f"Job Title: {expert.job_title or 'N/A'}\n"
        f"Bio: {expert.bio}\n\n"
        f"Example tags: 'machine learning', 'tax law', 'veterinary', 'crypto', "
        f"'real estate', 'supply chain', 'fundraising', 'climate tech'\n\n"
        f"Return tags that reflect their actual domain — not generic business terms."
    )
    response = await client.aio.models.generate_content(
        model=MODEL,
        contents=prompt,
        config=types.GenerateContentConfig(
            response_mime_type="application/json",
            response_schema=ExpertTags,
            temperature=0.2,
        ),
    )
    data = ExpertTags.model_validate_json(response.text)
    # Normalize: lowercase + strip. Locked decision from CONTEXT.md.
    return [t.lower().strip() for t in data.tags if t.strip()]


# ── Batch runner ───────────────────────────────────────────────────────────────

async def run_batch() -> None:
    client = genai.Client()
    semaphore = asyncio.Semaphore(CONCURRENCY)

    untagged = _load_untagged_experts()

    if not untagged:
        print("All experts already tagged. Nothing to do.")
        return

    # Separate experts with bio (can be tagged) from those without (skip Gemini)
    with_bio = [e for e in untagged if (e.bio or "").strip()]
    no_bio = [e for e in untagged if not (e.bio or "").strip()]

    failures: list[tuple[str, str]] = []  # (username, error_message)

    async def process_one(expert: Expert, pbar: async_tqdm) -> None:
        async with semaphore:
            try:
                tags = await _call_gemini_for_tags(client, expert)
            except Exception as e:
                # Retry once on failure
                try:
                    tags = await _call_gemini_for_tags(client, expert)
                except Exception as e2:
                    failures.append((expert.username, str(e2)))
                    pbar.update(1)
                    return

            score = compute_findability_score(expert, tags)
            _write_tags_to_db(expert.id, tags, score)
            pbar.update(1)

    # Tag experts with bio
    if with_bio:
        # total shows all untagged including no-bio for accurate count display
        with async_tqdm(total=len(untagged), desc="Tagging") as pbar:
            await asyncio.gather(*[process_one(e, pbar) for e in with_bio])
            # Advance bar for no-bio experts (skipped, not tagged)
            for _ in no_bio:
                pbar.update(1)

    # Compute findability scores for no-bio experts (tags=None → 0 pts for tags component)
    for expert in no_bio:
        score = compute_findability_score(expert, tags=None)
        _write_score_to_db(expert.id, score)

    # Print summary only if there were failures or skips
    if failures or no_bio:
        print()
        if no_bio:
            print(f"Skipped {len(no_bio)} experts with no bio (findability score computed, no tags generated)")
        if failures:
            print(f"Failed {len(failures)} experts after retry:")
            for username, err in failures:
                print(f"  - {username}: {err}")


if __name__ == "__main__":
    asyncio.run(run_batch())
```

Key implementation notes:
- Do NOT hold a SessionLocal open across any `await` call. The pattern above opens a fresh session only in sync helper functions (_load_untagged_experts, _write_tags_to_db etc.) — all sessions are closed before any async Gemini call. This prevents SQLite "objects created in a thread" errors.
- CONCURRENCY=5 is the documented conservative default. The constant is at the top of the file so admins can tune it.
- tqdm import: use `from tqdm.asyncio import tqdm as async_tqdm` — this works with asyncio.gather.
- The no-bio skip loop runs after the tagged experts have been processed; it writes findability scores synchronously (no async needed — no Gemini call).
  </action>
  <verify>
Run: python -c "import ast; ast.parse(open('scripts/tag_experts.py').read()); print('syntax ok')"
Expected: syntax ok

Run: python -c "
import sys; sys.path.insert(0, '.')
from scripts.tag_experts import _load_untagged_experts, compute_findability_score
print('imports ok')
"
Expected: imports ok (may print a dotenv warning if no .env file, that is fine)

Run: python scripts/tag_experts.py --help 2>&1 || python -c "import scripts.tag_experts" — should import without error.
  </verify>
  <done>scripts/tag_experts.py exists, has valid Python syntax, imports from app.database and app.services.tagging without error, and implements the async batch pattern with tqdm progress, CONCURRENCY semaphore, retry-once-then-skip logic, and findability scoring for no-bio experts.</done>
</task>

</tasks>

<verification>
1. python -c "import ast; ast.parse(open('scripts/tag_experts.py').read()); print('ok')" → ok
2. grep "tqdm" requirements.txt → tqdm==4.66.*
3. python -c "from scripts.tag_experts import _load_untagged_experts" → no ImportError
4. Manual code review confirms: no SessionLocal is held open across an await call (all DB helpers are sync functions)
5. Manual code review confirms: no-bio experts receive a findability_score write but no Gemini call
6. Manual code review confirms: CONCURRENCY constant at top of file with comment pointing to AI Studio RPM docs
</verification>

<success_criteria>
- scripts/tag_experts.py exists with valid Python syntax
- tqdm==4.66.* in requirements.txt
- Script uses asyncio + semaphore for CONCURRENCY=5 parallel Gemini calls
- Skips experts with no bio (no Gemini call, still writes findability score)
- Skips already-tagged experts (tags IS NOT NULL) — idempotent re-runs
- Retry-once-then-skip pattern for individual failures
- Progress bar shows total count (including no-bio skips)
- Run summary printed only on failures or skips
- compute_findability_score imported from app.services.tagging (shared module)
</success_criteria>

<output>
After completion, create `.planning/phases/08-test-lab-run-queries-against-search-engine-evaluate-results-iterate-on-retrieval-quality/08-02-SUMMARY.md`
</output>
