---
phase: 28-sage-search-engine
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - app/routers/pilot.py
  - app/services/pilot_service.py
  - app/routers/admin.py
autonomous: true
requirements:
  - SAGE-01
  - SAGE-03
  - SAGE-04

must_haves:
  truths:
    - "Calling POST /api/pilot with a discovery query (e.g. 'find me fintech experts') returns search_performed: true and a non-empty message"
    - "Calling POST /api/pilot with a refinement query (e.g. 'narrow to $150/hr') returns search_performed: false and filters dict"
    - "When search_experts finds zero results, the response contains filters: null and message acknowledges zero results with a fallback suggestion"
    - "When search_experts finds zero results AND fallback also finds zero, response contains filters: {reset: true} and message states no match found"
    - "Railway logs show fn_call.name for every /api/pilot request (verifiable after deploy)"
  artifacts:
    - path: "app/routers/pilot.py"
      provides: "Updated pilot endpoint injecting db + app_state into run_pilot()"
      contains: "Depends(get_db)"
    - path: "app/services/pilot_service.py"
      provides: "search_experts FunctionDeclaration, _handle_search_experts(), updated run_pilot() signature"
      contains: "SEARCH_EXPERTS_DECLARATION"
  key_links:
    - from: "app/routers/pilot.py"
      to: "app/services/pilot_service.py"
      via: "run_pilot(db=db, app_state=request.app.state)"
      pattern: "run_pilot.*db=db.*app_state"
    - from: "app/services/pilot_service.py"
      to: "app/services/explorer.py"
      via: "run_explore() direct Python import"
      pattern: "from app.services.explorer import run_explore"
---

<objective>
Add the `search_experts` Gemini function tool to the backend pilot service. Sage can now find experts by calling `run_explore()` in-process, narrate results, and signal the frontend to sync the grid.

Purpose: This is the backend half of Sage's search capability. Without it, Sage can only refine filters — it cannot discover experts from scratch.
Output: Updated `pilot.py` (db/app_state injection), updated `pilot_service.py` (new FunctionDeclaration + handler + response shape), verified in Railway logs via 20-query test.
</objective>

<execution_context>
@/Users/sebastianhamers/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sebastianhamers/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/28-sage-search-engine/28-CONTEXT.md
@.planning/phases/28-sage-search-engine/28-RESEARCH.md
@app/routers/pilot.py
@app/services/pilot_service.py
@app/services/explorer.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Inject db + app_state into pilot.py router</name>
  <files>app/routers/pilot.py</files>
  <action>
Update the `pilot` endpoint in `app/routers/pilot.py` to inject `db: Session = Depends(get_db)` and `request: Request` as parameters, following the exact same pattern as `app/routers/explore.py`.

Changes required:
1. Add imports: `from fastapi import APIRouter, Depends, Request` (add `Request` if not present), `from sqlalchemy.orm import Session`, `from app.database import get_db`
2. Update the `@router.post("/api/pilot")` handler signature to add `request: Request` and `db: Session = Depends(get_db)` parameters
3. Update the `run_in_executor` lambda to pass `db=db` and `app_state=request.app.state` to `run_pilot()`

The executor lambda pattern must look like:
```python
lambda: run_pilot(
    message=body.message,
    history=[h.model_dump() for h in body.history],
    current_filters=body.current_filters,
    db=db,
    app_state=request.app.state,
)
```

Do NOT add `asyncio.get_event_loop()` if `run_in_executor` already uses a different async pattern — match whatever event loop pattern already exists in the file.

Also update `PilotResponse` model (likely in `app/models.py` or inline in `pilot.py`) to add the three new fields:
- `experts: list[dict] | None = None`
- `total: int | None = None`
- `search_performed: bool = False`

If `PilotResponse` is defined in `app/models.py`, update it there. If defined in `pilot.py`, update it there. Check the file before assuming location.
  </action>
  <verify>
Run `cd /Users/sebastianhamers/Documents/TCS && python -c "from app.routers.pilot import router; print('pilot import OK')"` — must print "pilot import OK" with no errors.
  </verify>
  <done>pilot.py imports cleanly; PilotResponse has search_performed, total, experts fields; endpoint signature accepts db and request.</done>
</task>

<task type="auto">
  <name>Task 2: Add search_experts function and handler to pilot_service.py</name>
  <files>app/services/pilot_service.py</files>
  <action>
Update `app/services/pilot_service.py` to add `search_experts` as a second Gemini FunctionDeclaration alongside the existing `apply_filters`, implement `_handle_search_experts()`, update `run_pilot()` signature, and update the system prompt.

**Step 1 — Update `run_pilot()` signature:**
```python
def run_pilot(
    message: str,
    history: list[dict],
    current_filters: dict,
    db,        # SQLAlchemy Session — passed from pilot.py router
    app_state, # FastAPI app.state — FAISS index + metadata
) -> dict:
```

**Step 2 — Add `SEARCH_EXPERTS_DECLARATION`:**
```python
SEARCH_EXPERTS_DECLARATION = types.FunctionDeclaration(
    name="search_experts",
    description=(
        "Discover experts matching a specific need. Use when the user wants to find experts "
        "from scratch: 'find me X', 'who can help with Y', 'show me Z experts', 'I need someone who'. "
        "Performs a live search and returns matched experts."
    ),
    parameters_json_schema={
        "type": "object",
        "properties": {
            "query": {
                "type": "string",
                "description": "Natural language description of the expert needed.",
            },
            "rate_min": {"type": "number", "description": "Minimum hourly rate filter."},
            "rate_max": {"type": "number", "description": "Maximum hourly rate filter."},
            "tags": {
                "type": "array",
                "items": {"type": "string"},
                "description": "Domain tags to filter by (AND logic).",
            },
        },
        "required": ["query"],
    },
)
```

Update the existing `apply_filters` description to be explicitly narrow:
"Narrow or refine the current expert results based on user-specified criteria (rate, tags, keywords). Use when the user is adjusting or narrowing what they already see — NOT when discovering experts from scratch."

**Step 3 — Include both declarations in the Tool:**
```python
tool = types.Tool(function_declarations=[
    APPLY_FILTERS_DECLARATION,
    SEARCH_EXPERTS_DECLARATION,
])
```

**Step 4 — Update system prompt** to include both function descriptions and narration guidance:
```python
system_instruction = (
    "You are Sage, a warm and helpful AI assistant for a professional expert marketplace. "
    "You have two tools:\n"
    "- apply_filters: narrow or refine what the user currently sees\n"
    "- search_experts: discover experts from scratch when the user asks to find, show, or explore experts\n\n"
    "When search_experts returns results, narrate like: "
    "'Found {N} {domain} experts, including {Name1} and {Name2}, with backgrounds in {skill1}, {skill2}. Updated the grid for you.'\n"
    "For large result sets (100+), mention the size and offer to narrow.\n"
    "For zero results, acknowledge and suggest the closest alternative found. Be specific — mention the alternative's rate or count.\n"
    "Do not restate the filters you applied. Be warm and concise.\n"
    f"Current active filters: {current_filters}."
)
```

**Step 5 — Add routing branch in `run_pilot()`:**
After `fn_call = response.function_calls[0]` and `args = dict(fn_call.args)`:
```python
if fn_call.name == "search_experts":
    return _handle_search_experts(fn_call, args, response, contents, config, db, app_state, client)
elif fn_call.name == "apply_filters":
    return _handle_apply_filters(fn_call, args, response, contents, config, client)
```

Note: pass `response` (Turn 1 result) into the handlers so they can append `response.candidates[0].content` to contents for Turn 2.

**Step 6 — Implement `_handle_search_experts()`:**
```python
def _handle_search_experts(fn_call, args, response, contents, config, db, app_state, client) -> dict:
    from app.services.explorer import run_explore

    result = run_explore(
        query=args.get("query", ""),
        rate_min=float(args.get("rate_min", 0.0)),
        rate_max=float(args.get("rate_max", 10000.0)),
        tags=list(args.get("tags", [])),
        limit=20,
        cursor=0,
        db=db,
        app_state=app_state,
    )

    if result.total == 0:
        # Fallback: relax all constraints except query
        fallback = run_explore(
            query=args.get("query", ""),
            rate_min=0.0,
            rate_max=10000.0,
            tags=[],
            limit=5,
            cursor=0,
            db=db,
            app_state=app_state,
        )
        if fallback.total == 0:
            fn_response = {"result": "zero_results", "fallback": "none"}
            filters_to_apply = {"reset": True}
        else:
            top = fallback.experts[:2]
            fn_response = {
                "result": "zero_results",
                "fallback_count": fallback.total,
                "fallback_examples": [
                    f"{e.first_name} {e.last_name} (${e.hourly_rate:.0f}/hr)"
                    for e in top
                ],
            }
            filters_to_apply = None  # Grid stays as-is per locked decision
    else:
        top = result.experts[:2]
        fn_response = {
            "result": "success",
            "total": result.total,
            "top_experts": [
                {
                    "name": f"{e.first_name} {e.last_name}",
                    "title": e.job_title,
                    "rate": e.hourly_rate,
                    "tags": e.tags[:3],
                }
                for e in top
            ],
        }
        filters_to_apply = {
            "query": args.get("query", ""),
            "rate_min": float(args.get("rate_min", 0.0)),
            "rate_max": float(args.get("rate_max", 10000.0)),
            "tags": list(args.get("tags", [])),
        }

    # Turn 2: send function result back → Gemini generates narration
    contents.append(response.candidates[0].content)
    contents.append(types.Content(
        role="user",
        parts=[types.Part.from_function_response(
            name="search_experts",
            response=fn_response,
        )]
    ))
    final = client.models.generate_content(
        model=GENERATION_MODEL, contents=contents, config=config
    )
    narration = final.text or "I found some experts matching your request — check the grid!"

    log.info(
        "pilot: search_experts executed",
        fn_name=fn_call.name,
        total=result.total,
        query=args.get("query", ""),
    )

    return {
        "filters": filters_to_apply,
        "message": narration,
        "search_performed": True,
        "total": result.total,
    }
```

**Critical reminders (from research pitfalls):**
- `args = dict(fn_call.args)` — always unwrap protobuf Struct before use
- `float(args.get("rate_min", 0.0))` and `list(args.get("tags", []))` — defensive casting for protobuf nested types
- Pass `response` (Turn 1 object) as parameter to `_handle_search_experts()` so `response.candidates[0].content` is in scope for Turn 2
- Do NOT call `setResults()` — that is for the frontend only and belongs to `resultsSlice` exclusively
- If `_handle_apply_filters()` already exists as a helper, ensure it also receives `response` for Turn 2 consistency; if it's inline, refactor consistently
  </action>
  <verify>
Run `cd /Users/sebastianhamers/Documents/TCS && python -c "from app.services.pilot_service import run_pilot, SEARCH_EXPERTS_DECLARATION; print('pilot_service import OK')"` — must print without errors.

Also verify: `grep -n "search_experts" /Users/sebastianhamers/Documents/TCS/app/services/pilot_service.py` shows at least 3 occurrences (declaration, tool registration, branch condition).
  </verify>
  <done>pilot_service.py imports cleanly; SEARCH_EXPERTS_DECLARATION defined; _handle_search_experts() implemented with zero-result fallback; run_pilot() signature accepts db + app_state; fn_call.name logged on every call.</done>
</task>

</tasks>

<verification>
1. `python -c "from app.routers.pilot import router"` — no ImportError
2. `python -c "from app.services.pilot_service import run_pilot, SEARCH_EXPERTS_DECLARATION"` — no ImportError
3. `grep "fn_call.name" app/services/pilot_service.py` — confirms fn_name is logged
4. `grep "from app.services.explorer import run_explore" app/services/pilot_service.py` — confirms direct import (no HTTP self-call)
5. `grep "search_performed" app/services/pilot_service.py` — confirms field in return dict
</verification>

<success_criteria>
- POST /api/pilot with discovery intent returns search_performed: true, narrated message, and filters dict (or null on zero results)
- POST /api/pilot with refinement intent returns search_performed: false and filters dict
- Zero results triggers fallback search; double-zero triggers {reset: true}; grid stays as-is on single-zero
- fn_call.name appears in every pilot log entry for Railway verification
- No HTTP self-call to /api/explore — only direct Python import of run_explore()
</success_criteria>

<output>
After completion, create `.planning/phases/28-sage-search-engine/28-01-SUMMARY.md`
</output>
