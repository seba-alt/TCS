---
phase: 02-rag-api
plan: 03
type: execute
wave: 2
depends_on:
  - "02-01"
  - "02-02"
files_modified:
  - app/routers/chat.py
  - app/routers/__init__.py
  - app/main.py
autonomous: true
requirements:
  - REC-02

must_haves:
  truths:
    - "POST /api/chat with {email, query} returns JSON with narrative, exactly 3 experts, and type=match"
    - "POST /api/chat with a missing email field returns 422 Unprocessable Entity"
    - "POST /api/chat with a vague query returns type=clarification with a follow-up question and empty experts array"
    - "Every successful POST /api/chat creates a row in the conversations table"
    - "POST /api/chat with {email, query, history} uses prior conversation turns as context"
  artifacts:
    - path: "app/routers/chat.py"
      provides: "POST /api/chat endpoint with Pydantic validation, retrieval, generation, and DB logging"
      exports: ["router"]
      contains: "email"
    - path: "app/main.py"
      provides: "chat router registered on the FastAPI app"
      contains: "chat.router"
  key_links:
    - from: "app/routers/chat.py"
      to: "app/services/retriever.py"
      via: "retrieve(query, request.app.state.faiss_index, request.app.state.metadata)"
      pattern: "retrieve\\("
    - from: "app/routers/chat.py"
      to: "app/services/llm.py"
      via: "generate_response(query, candidates, history)"
      pattern: "generate_response\\("
    - from: "app/routers/chat.py"
      to: "app/models.py"
      via: "db.add(Conversation(...)); db.commit()"
      pattern: "db\\.add\\(Conversation"
---

<objective>
Wire the retriever and LLM services into a POST /api/chat HTTP endpoint with email validation, conversation history support, and database logging. This is the non-streaming version — verified end-to-end before the SSE upgrade in Plan 04.

Purpose: The non-streaming endpoint validates the full RAG pipeline (embed → retrieve → generate → store) in isolation. Once this endpoint returns correct results, the streaming upgrade in Plan 04 is purely a delivery mechanism change — no logic changes required.
Output: POST /api/chat endpoint returning complete JSON responses; conversations logged to SQLite.
</objective>

<execution_context>
@/Users/sebastianhamers/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sebastianhamers/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-rag-api/02-CONTEXT.md
@app/main.py
@app/services/retriever.py
@app/services/llm.py
@app/database.py
@app/models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create POST /api/chat router with email validation, retrieval, generation, and DB logging</name>
  <files>app/routers/chat.py</files>
  <action>
    Create app/routers/chat.py:

    ```python
    """
    POST /api/chat — non-streaming expert recommendation endpoint.

    Request body:
        email (str, required): User's email address. API enforces presence — lead capture requirement.
        query (str, required): Natural language problem description.
        history (list[dict], optional): Prior conversation turns for multi-turn context.
                                        Each item: {"role": "user"|"assistant", "content": str}

    Response body (200 OK):
        {
            "type": "match" | "clarification",
            "narrative": "...",
            "experts": [
                {"name": ..., "title": ..., "company": ..., "hourly_rate": ..., "profile_url": ...},
                ...  # exactly 3 for type="match", empty list for type="clarification"
            ]
        }

    Error responses:
        422: Missing email or query (Pydantic validation)
        500: Gemini generation failure after all retries exhausted
    """
    import json

    import structlog
    from fastapi import APIRouter, Depends, HTTPException, Request
    from pydantic import BaseModel, EmailStr, Field
    from sqlalchemy.orm import Session

    from app.database import get_db
    from app.models import Conversation
    from app.services.llm import Expert, generate_response
    from app.services.retriever import retrieve

    log = structlog.get_logger()
    router = APIRouter()


    class HistoryItem(BaseModel):
        role: str  # "user" | "assistant"
        content: str


    class ChatRequest(BaseModel):
        email: EmailStr  # Pydantic validates email format; returns 422 if missing or malformed
        query: str = Field(..., min_length=1, max_length=2000)
        history: list[HistoryItem] = Field(default_factory=list)


    class ExpertOut(BaseModel):
        name: str
        title: str
        company: str
        hourly_rate: str
        profile_url: str | None


    class ChatResponse(BaseModel):
        type: str
        narrative: str
        experts: list[ExpertOut]


    @router.post("/api/chat", response_model=ChatResponse)
    async def chat(
        body: ChatRequest,
        request: Request,
        db: Session = Depends(get_db),
    ) -> ChatResponse:
        """
        Accept a user query, retrieve matched experts via FAISS, generate recommendations
        via Gemini, log the conversation, and return the structured response.
        """
        log.info("chat.request", email=body.email, query_length=len(body.query))

        # 1. Retrieve expert candidates from FAISS
        candidates = retrieve(
            query=body.query,
            faiss_index=request.app.state.faiss_index,
            metadata=request.app.state.metadata,
        )
        log.info("chat.retrieved", candidate_count=len(candidates))

        # 2. Generate response via Gemini (with retry on failure)
        history_dicts = [{"role": h.role, "content": h.content} for h in body.history]
        try:
            llm_response = generate_response(
                query=body.query,
                candidates=candidates,
                history=history_dicts,
            )
        except RuntimeError as exc:
            log.error("chat.llm_failure", error=str(exc))
            raise HTTPException(status_code=500, detail="Failed to generate response. Please try again.")

        # 3. Log conversation to database (lead capture + analytics requirement)
        conversation = Conversation(
            email=str(body.email),
            query=body.query,
            history=json.dumps(history_dicts),
            response_type=llm_response.type,
            response_narrative=llm_response.narrative,
            response_experts=json.dumps(
                [
                    {
                        "name": e.name,
                        "title": e.title,
                        "company": e.company,
                        "hourly_rate": e.hourly_rate,
                        "profile_url": e.profile_url,
                    }
                    for e in llm_response.experts
                ]
            ),
        )
        db.add(conversation)
        db.commit()
        log.info("chat.logged", conversation_id=conversation.id)

        # 4. Build and return response
        experts_out = [
            ExpertOut(
                name=e.name,
                title=e.title,
                company=e.company,
                hourly_rate=e.hourly_rate,
                profile_url=e.profile_url,
            )
            for e in llm_response.experts
        ]

        return ChatResponse(
            type=llm_response.type,
            narrative=llm_response.narrative,
            experts=experts_out,
        )
    ```

    Note on EmailStr: FastAPI/Pydantic v2's EmailStr requires `email-validator` package. Add `email-validator==2.1.*` to requirements.txt and run `pip install "email-validator==2.1.*"`.
  </action>
  <verify>
    Run: `python -c "from app.routers.chat import router, ChatRequest, ChatResponse; print('Chat router OK:', len(router.routes), 'routes')"`
    Expected: prints "Chat router OK: 1 routes"
  </verify>
  <done>app/routers/chat.py importable; POST /api/chat route defined; ChatRequest requires email (EmailStr) and query; history optional; DB logging via Conversation model.</done>
</task>

<task type="auto">
  <name>Task 2: Register chat router, start server, and verify end-to-end</name>
  <files>app/main.py</files>
  <action>
    1. Add the chat router import and registration to app/main.py. In the imports section, add:
    ```python
    from app.routers import chat
    ```
    In the Routes section (after the existing health router line), add:
    ```python
    app.include_router(chat.router)
    ```
    Keep all existing code intact.

    2. Start the FastAPI server:
    ```bash
    uvicorn app.main:app --reload --port 8000
    ```

    3. Run the following curl tests to verify end-to-end. The server must be running:

    Test A — Valid request (expect 200 with match or clarification):
    ```bash
    curl -s -X POST http://localhost:8000/api/chat \
      -H "Content-Type: application/json" \
      -d '{"email": "test@example.com", "query": "I need a machine learning engineer for my startup"}' \
      | python3 -m json.tool
    ```
    Expected: 200 response with `"type"`, `"narrative"`, and `"experts"` fields.

    Test B — Missing email (expect 422):
    ```bash
    curl -s -X POST http://localhost:8000/api/chat \
      -H "Content-Type: application/json" \
      -d '{"query": "I need a machine learning engineer"}' \
      | python3 -m json.tool
    ```
    Expected: 422 response.

    Test C — Missing query (expect 422):
    ```bash
    curl -s -X POST http://localhost:8000/api/chat \
      -H "Content-Type: application/json" \
      -d '{"email": "test@example.com"}' \
      | python3 -m json.tool
    ```
    Expected: 422 response.

    Test D — Verify DB logging (after Test A succeeds):
    ```bash
    python3 -c "
    from app.database import SessionLocal
    from app.models import Conversation
    db = SessionLocal()
    convs = db.query(Conversation).all()
    print(f'Conversations in DB: {len(convs)}')
    if convs:
        c = convs[-1]
        print(f'Latest: email={c.email}, type={c.response_type}, experts_count={len(__import__(\"json\").loads(c.response_experts))}')
    db.close()
    "
    ```
    Expected: shows at least 1 conversation logged with the test email.

    4. Stop the uvicorn server after verification is complete.
  </action>
  <verify>
    All four tests above pass:
    - Test A returns 200 with type, narrative, experts fields
    - Test B returns 422
    - Test C returns 422
    - Test D shows conversation logged in DB
  </verify>
  <done>POST /api/chat registered on FastAPI app; returns 200 with structured JSON for valid requests; 422 for missing email or query; conversation written to SQLite after each successful request.</done>
</task>

</tasks>

<verification>
Full end-to-end verification (server must be running on port 8000):

1. Health check still works: `curl -s http://localhost:8000/api/health | python3 -m json.tool` → 200 with index_size > 0
2. Chat endpoint responds: `curl -s -X POST http://localhost:8000/api/chat -H "Content-Type: application/json" -d '{"email":"verify@test.com","query":"I need a financial advisor for my tech startup"}' | python3 -m json.tool`
   → 200 with type, narrative, experts
3. Response has correct structure: `type` is "match" or "clarification"; `narrative` is non-empty string; `experts` is a list
4. If type="match": `experts` array has exactly 3 items, each with name, title, company, hourly_rate, profile_url fields
5. Missing email returns 422; missing query returns 422
6. DB check: query shows the new conversation row with the verify@test.com email
7. Phase 1 endpoint unchanged: `curl -s http://localhost:8000/api/health` still returns 200
</verification>

<success_criteria>
- POST /api/chat endpoint returns 200 with {type, narrative, experts} for valid requests
- Pydantic validation rejects missing email with 422 (EmailStr enforcement)
- Pydantic validation rejects missing query with 422
- Every 200 response creates a Conversation row in SQLite
- Multi-turn history accepted in request body and passed to generate_response()
- Phase 1 /api/health endpoint unaffected
- gemini-2.5-flash model used (confirmed via llm.py GENERATION_MODEL)
</success_criteria>

<output>
After completion, create `.planning/phases/02-rag-api/02-03-SUMMARY.md`
</output>
