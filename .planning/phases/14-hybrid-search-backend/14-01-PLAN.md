---
phase: 14-hybrid-search-backend
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - app/services/explorer.py
  - app/routers/explore.py
autonomous: true
requirements:
  - EXPL-01
  - EXPL-02
  - EXPL-03
  - EXPL-04

must_haves:
  truths:
    - "GET /api/explore returns ExploreResponse JSON with experts[], total, cursor, and took_ms"
    - "With a text query, results are ranked by fused FAISS (0.7) + BM25 (0.3) score with findability boost applied"
    - "Without a text query, results are sorted by findability_score descending (pure filter mode, no FAISS/FTS5)"
    - "Rate range and tag filters restrict results before FAISS search via SQLAlchemy WHERE + IDSelectorBatch"
    - "Each ExpertCard includes faiss_score, bm25_score, final_score, and match_reason (None when query is empty)"
  artifacts:
    - path: "app/services/explorer.py"
      provides: "ExpertCard schema, ExploreResponse schema, run_explore() pipeline"
      exports: ["ExpertCard", "ExploreResponse", "run_explore"]
    - path: "app/routers/explore.py"
      provides: "GET /api/explore FastAPI route"
      exports: ["router"]
  key_links:
    - from: "app/routers/explore.py"
      to: "app/services/explorer.py"
      via: "run_explore() called in executor"
      pattern: "run_explore"
    - from: "app/services/explorer.py"
      to: "app.state.username_to_faiss_pos"
      via: "app_state.username_to_faiss_pos lookup"
      pattern: "username_to_faiss_pos"
    - from: "app/services/explorer.py"
      to: "experts_fts"
      via: "db.execute(text('SELECT rowid, rank FROM experts_fts ...'))"
      pattern: "experts_fts"
---

<objective>
Create the hybrid search pipeline service and its FastAPI router. This produces the ExploreResponse data contract that all downstream marketplace phases (15–19) build against.

Purpose: The pipeline is the core engine of Phase 14 — three-stage search (SQLAlchemy pre-filter → FAISS IDSelectorBatch → FTS5 BM25 fusion) with findability boost and pagination.
Output: app/services/explorer.py (pipeline + Pydantic schemas), app/routers/explore.py (thin GET /api/explore route)
</objective>

<execution_context>
@/Users/sebastianhamers/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sebastianhamers/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-hybrid-search-backend/14-CONTEXT.md
@.planning/phases/14-hybrid-search-backend/14-RESEARCH.md
@app/models.py
@app/main.py
@app/routers/admin.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create explorer.py hybrid search pipeline service</name>
  <files>app/services/explorer.py</files>
  <action>
Create app/services/explorer.py from scratch with the full three-stage hybrid search pipeline. Follow the RESEARCH.md patterns exactly.

**Pydantic schemas (define at top of file):**

```python
class ExpertCard(BaseModel):
    username: str
    first_name: str
    last_name: str
    job_title: str
    company: str
    hourly_rate: float
    currency: str
    profile_url: str          # profile_url_utm preferred; fallback to profile_url
    tags: list[str]
    findability_score: float | None
    category: str | None
    faiss_score: float | None   # None in pure filter mode
    bm25_score: float | None    # None in pure filter mode
    final_score: float          # findability-boosted fused score (or findability_score in filter mode)
    match_reason: str | None    # None when query is empty

class ExploreResponse(BaseModel):
    experts: list[ExpertCard]
    total: int          # pre-filter count (before pagination)
    cursor: int | None  # next offset; None = no more pages
    took_ms: int
```

**Constants (hardcoded — no env vars):**
```python
FAISS_WEIGHT = 0.7
BM25_WEIGHT = 0.3
ITEMS_PER_PAGE = 20
```

**FTS5 query sanitizer (add before run_explore):**
```python
def _safe_fts_query(query: str) -> str:
    import re
    cleaned = re.sub(r'[()"\*\+]', ' ', query)
    cleaned = re.sub(r'\b(AND|OR|NOT)\b', ' ', cleaned, flags=re.IGNORECASE)
    words = cleaned.split()[:10]
    return " ".join(words) if words else ""
```

**run_explore() function** — implement the three-stage pipeline:

Stage 1 (always runs): SQLAlchemy pre-filter with hourly_rate range AND all tags (AND logic). Tag matching uses `Expert.tags.like(f'%"{tag.lower()}"%')` (normalize tags to lowercase). Collect `filtered_experts: list[Expert]` and set `total = len(filtered_experts)`. Return empty ExploreResponse immediately if filtered_experts is empty.

Stage 2 (text query only): FAISS IDSelectorBatch search.
- Build `allowed_positions` from `username_to_faiss_pos` for experts in `filtered_experts` that have a mapping entry.
- Guard: if `len(allowed_positions) == 0`, set `faiss_scores = {}` and skip search.
- Otherwise: embed query, construct `faiss.IDSelectorBatch(allowed_positions)`, `faiss.SearchParameters(sel=selector)`, call `faiss_index.search(query_vec, k, params=params)` where `k = min(50, len(allowed_positions))`.
- Map result indices back to username via `app_state.metadata[pos].get("Username", "")`.
- Store as `faiss_scores: dict[str, float]`.

Stage 3 (text query only): FTS5 BM25 query.
- Run `_safe_fts_query(query)`. If result is empty string, set `bm25_scores = {}` and skip.
- Query: `SELECT rowid, rank FROM experts_fts WHERE experts_fts MATCH :q ORDER BY rank LIMIT 200`
- Filter to `filtered_ids = {e.id for e in filtered_experts}` (only pre-filtered experts).
- Normalize BM25: rank is negative (lower = more relevant). `abs(rank)`, then normalize 0.0–1.0 by dividing by max. Result: `bm25_scores: dict[int, float]` keyed by Expert.id.

Score fusion:
- For each expert in `filtered_experts`: get `fs = faiss_scores.get(expert.username, 0.0)`, `bs = bm25_scores.get(expert.id, 0.0)`. Skip (exclude from hybrid results) if both are 0.0. Fuse: `(fs * FAISS_WEIGHT) + (bs * BM25_WEIGHT)`. Apply `_apply_findability_boost()`. Collect as `(final_score, faiss_score, bm25_score, expert)` tuples. Sort descending by `final_score`.

Pure filter mode (no text query): Sort `filtered_experts` by `findability_score or 0.0` descending.

Pagination for both modes: slice `[cursor:cursor+limit+1]`, `has_more = len(page) > limit`, trim to `limit`, `next_cursor = cursor + limit if has_more else None`.

Build cards via `_build_card()` helper.

**_apply_findability_boost():**
Multiplicative: normalize findability_score from 50–100 range to -1.0 to +1.0. `normalized = (findability_score - 75.0) / 25.0`. `multiplier = 1.0 + (normalized * 0.20)` → range 0.8–1.2. Return `fused_score * multiplier`. Return `fused_score` unchanged if `findability_score is None`.

**_build_card():**
- Parse `tags = json.loads(expert.tags or "[]")`
- `match_reason = _build_match_reason(expert, tags, query) if query.strip() else None`
- Use `expert.profile_url_utm or expert.profile_url` for profile_url
- Round `final_score` to 4 decimal places

**_build_match_reason():** Tag intersection approach (no Gemini — deterministic, zero latency).
- Return None if query is empty.
- `query_lower = query.lower()`
- `matched_tags = [t for t in tags if t.lower() in query_lower][:3]`
- If matched_tags: return `"Strong match: " + ", ".join(matched_tags)`
- Else if `expert.job_title`: return `f"Match via: {expert.job_title}"`
- Else: return None

**Imports needed:** `time`, `json`, `re`, `typing`, `numpy`, `faiss`, `sqlalchemy.select`, `sqlalchemy.and_`, `sqlalchemy.text`, `sqlalchemy.orm.Session`, `pydantic.BaseModel`, `app.models.Expert`, `app.services.embedder.embed_query`, `structlog`

**CRITICAL pitfall avoidance (from RESEARCH.md):**
- NEVER call `index.remove_ids()` — use search-time IDSelectorBatch via SearchParameters only
- Guard `len(allowed_positions) == 0` before constructing IDSelectorBatch
- Always use `username_to_faiss_pos[expert.username]` (not `expert.id`) for FAISS position
- Always use `LIMIT 200` on FTS5 queries
- Always apply `_safe_fts_query()` before FTS5 MATCH to handle special chars
  </action>
  <verify>
    Run: `python -c "from app.services.explorer import ExpertCard, ExploreResponse, run_explore; print('explorer.py imports OK')"` from project root.
    Expected: "explorer.py imports OK" with no errors.
  </verify>
  <done>
    app/services/explorer.py exists, imports cleanly, and exports ExpertCard, ExploreResponse, and run_explore.
    All three pipeline stages (SQLAlchemy pre-filter, FAISS IDSelectorBatch, FTS5 BM25) are implemented.
    Pure filter mode (no text query) sorts by findability_score descending without touching FAISS or FTS5.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create explore.py thin FastAPI router</name>
  <files>app/routers/explore.py</files>
  <action>
Create app/routers/explore.py — a thin FastAPI router that delegates to run_explore(). Follow RESEARCH.md Pattern 4 exactly.

```python
# app/routers/explore.py
import asyncio
from fastapi import APIRouter, Depends, Query, Request
from sqlalchemy.orm import Session
from app.database import get_db
from app.services.explorer import run_explore, ExploreResponse

router = APIRouter()


@router.get("/api/explore", response_model=ExploreResponse)
async def explore(
    request: Request,
    db: Session = Depends(get_db),
    query: str = Query(default="", max_length=500),
    rate_min: float = Query(default=0.0, ge=0),
    rate_max: float = Query(default=10000.0, le=10000),
    tags: str = Query(default=""),    # comma-separated, e.g. "seo,blockchain"
    limit: int = Query(default=20, ge=1, le=100),
    cursor: int = Query(default=0, ge=0),
) -> ExploreResponse:
    """
    Hybrid search: SQLAlchemy pre-filter → FAISS IDSelectorBatch → FTS5 BM25 → fused rank.
    When query is empty, returns experts sorted by findability_score (pure filter mode).
    Rate range: inclusive on both ends. Tags: comma-separated, AND logic (expert must have ALL).
    """
    tag_list = [t.strip() for t in tags.split(",") if t.strip()]
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(
        None,
        lambda: run_explore(
            query=query,
            rate_min=rate_min,
            rate_max=rate_max,
            tags=tag_list,
            limit=limit,
            cursor=cursor,
            db=db,
            app_state=request.app.state,
        )
    )
```

Note: `run_in_executor` offloads the synchronous pipeline (SQLAlchemy + FAISS + FTS5 numpy calls) to a thread pool, keeping the FastAPI event loop unblocked.
  </action>
  <verify>
    Run: `python -c "from app.routers.explore import router; print('explore router imports OK')"` from project root.
    Expected: "explore router imports OK" with no errors.
  </verify>
  <done>
    app/routers/explore.py exists with GET /api/explore route.
    Imports cleanly from app.services.explorer.
    Query params: query, rate_min, rate_max, tags (comma-separated), limit (default 20), cursor (default 0).
    run_explore() called via loop.run_in_executor to keep event loop unblocked.
  </done>
</task>

</tasks>

<verification>
After both tasks complete:
1. `python -c "from app.services.explorer import ExpertCard, ExploreResponse, run_explore; print('OK')"` — no ImportError
2. `python -c "from app.routers.explore import router; print('OK')"` — no ImportError
3. Review explorer.py: confirm IDSelectorBatch uses `allowed_positions` (dtype=np.int64), not Expert.id values
4. Review explorer.py: confirm FTS5 query has `LIMIT 200` and uses `_safe_fts_query()`
5. Review explorer.py: confirm `len(allowed_positions) == 0` guard exists before IDSelectorBatch construction
</verification>

<success_criteria>
- app/services/explorer.py exists and imports cleanly
- app/routers/explore.py exists and imports cleanly
- ExploreResponse has: experts[], total (int), cursor (int | None), took_ms (int)
- ExpertCard has: username, first_name, last_name, job_title, company, hourly_rate, currency, profile_url, tags, findability_score, category, faiss_score, bm25_score, final_score, match_reason
- Pure filter mode skips FAISS and FTS5 entirely
- Tag filtering uses AND logic with lowercase normalization
- Pagination: 20 per page default, cursor=None signals end of results
</success_criteria>

<output>
After completion, create .planning/phases/14-hybrid-search-backend/14-01-SUMMARY.md
</output>
