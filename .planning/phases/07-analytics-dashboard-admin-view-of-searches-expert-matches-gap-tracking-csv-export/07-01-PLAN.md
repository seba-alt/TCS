---
phase: 07-analytics-dashboard-admin-view-of-searches-expert-matches-gap-tracking-csv-export
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - app/models.py
  - app/main.py
  - app/routers/chat.py
  - app/routers/admin.py
  - app/routers/__init__.py
autonomous: true
requirements: [ANAL-01]

must_haves:
  truths:
    - "GET /api/admin/stats returns total_searches, match_count, match_rate, gap_count when X-Admin-Key header matches ADMIN_SECRET"
    - "GET /api/admin/searches returns paginated conversation rows with is_gap flag derived from top_match_score"
    - "GET /api/admin/gaps returns gap queries grouped by frequency with best_score and resolved status"
    - "POST /api/admin/gaps/{id}/resolve toggles gap_resolved=True on all conversations with that query text"
    - "GET /api/admin/export/searches.csv and GET /api/admin/export/gaps.csv return CSV downloads with metadata header rows"
    - "top_match_score is stored on every new conversation after schema change goes live"
    - "Requests without correct X-Admin-Key header receive 401 from all /api/admin/* endpoints"
  artifacts:
    - path: "app/routers/admin.py"
      provides: "All /api/admin/* endpoints with X-Admin-Key auth"
      exports: ["router"]
    - path: "app/models.py"
      provides: "top_match_score and gap_resolved columns on Conversation"
      contains: "top_match_score"
    - path: "app/main.py"
      provides: "ALTER TABLE migrations + admin router registration"
      contains: "admin"
  key_links:
    - from: "app/routers/chat.py"
      to: "app/models.py Conversation.top_match_score"
      via: "candidates[0].score captured before db.commit()"
      pattern: "top_match_score"
    - from: "app/main.py lifespan"
      to: "conversations table"
      via: "ALTER TABLE conversations ADD COLUMN top_match_score REAL"
      pattern: "ALTER TABLE conversations"
    - from: "app/routers/admin.py"
      to: "app/database.get_db"
      via: "Depends(get_db) on all endpoints"
      pattern: "Depends\\(get_db\\)"
---

<objective>
Add top_match_score and gap_resolved columns to the Conversation model, capture the score in chat.py, and build the complete /api/admin/* router with stats, searches, gaps, resolve, and CSV export endpoints guarded by X-Admin-Key header auth.

Purpose: Provide the data foundation the Phase 7 admin dashboard frontend will query. Without accurate gap scoring, the Gaps section cannot surface the "weak match" category the product requires.
Output: Five admin API endpoints + schema migration + score capture in chat flow.
</objective>

<execution_context>
@/Users/sebastianhamers/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sebastianhamers/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-analytics-dashboard-admin-view-of-searches-expert-matches-gap-tracking-csv-export/07-RESEARCH.md
@app/models.py
@app/main.py
@app/routers/chat.py
@app/database.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add top_match_score and gap_resolved to Conversation model + lifespan migrations + capture score in chat.py</name>
  <files>
    app/models.py
    app/main.py
    app/routers/chat.py
  </files>
  <action>
**app/models.py** — Add two nullable columns to the `Conversation` class after the `created_at` field:

```python
# After created_at mapped_column:
top_match_score: Mapped[float | None] = mapped_column(nullable=True)
gap_resolved: Mapped[bool] = mapped_column(nullable=False, default=False, server_default="0")
```

Add `Boolean` to the SQLAlchemy imports at the top of the file if it is not already imported (it likely is not — check the existing import line `from sqlalchemy import DateTime, String, Text` and add `Boolean` to it).

**app/main.py** — In the `lifespan` async function, after the `Base.metadata.create_all(bind=engine)` call and BEFORE the FAISS loading block, add an inline column migration block that safely adds both new columns to existing SQLite databases:

```python
# One-time column migrations for analytics schema — safe to leave in permanently.
# SQLite raises OperationalError if the column already exists; we catch and ignore.
from sqlalchemy import text as _text
with engine.connect() as _conn:
    for _col_ddl in [
        "ALTER TABLE conversations ADD COLUMN top_match_score REAL",
        "ALTER TABLE conversations ADD COLUMN gap_resolved INTEGER NOT NULL DEFAULT 0",
    ]:
        try:
            _conn.execute(_text(_col_ddl))
            _conn.commit()
        except Exception:
            pass  # Column already exists — idempotent
```

Place the import of `text` inside the lifespan body with an alias (`_text`) to avoid polluting the module namespace since `text` is already imported elsewhere in the project. Actually, add `text` to the existing sqlalchemy imports in main.py if they exist, or add it inline with alias as shown.

**app/routers/chat.py** — In `_stream_chat`, capture the top FAISS score immediately after `candidates` is resolved and before the `conversation = Conversation(...)` constructor:

```python
# Capture top FAISS score for gap analytics (None if no candidates)
top_score = candidates[0].score if candidates else None
```

Then pass it to the Conversation constructor:

```python
conversation = Conversation(
    email=str(body.email),
    query=body.query,
    history=json.dumps(history_dicts),
    response_type=llm_response.type,
    response_narrative=llm_response.narrative,
    response_experts=json.dumps(experts_payload),
    top_match_score=top_score,
)
```

No other changes to chat.py.
  </action>
  <verify>
Run: `cd /Users/sebastianhamers/Documents/TCS && python -c "from app.models import Conversation; print(hasattr(Conversation, 'top_match_score'), hasattr(Conversation, 'gap_resolved'))"`
Expected output: `True True`

Run: `cd /Users/sebastianhamers/Documents/TCS && python -c "from app.routers.chat import _stream_chat; import inspect; src = inspect.getsource(_stream_chat); print('top_match_score' in src)"`
Expected output: `True`
  </verify>
  <done>Conversation model has top_match_score (float nullable) and gap_resolved (bool default False) columns; lifespan applies ALTER TABLE migrations idempotently; chat.py captures candidates[0].score before DB commit.</done>
</task>

<task type="auto">
  <name>Task 2: Build /api/admin/* router with stats, searches, gaps, resolve, and CSV export endpoints</name>
  <files>
    app/routers/admin.py
    app/main.py
  </files>
  <action>
Create `app/routers/admin.py` with all admin endpoints. Use the exact patterns from the research doc.

**Gap threshold:** `GAP_THRESHOLD = 0.60` — matches `SIMILARITY_THRESHOLD` in retriever.py. A conversation is a gap if `top_match_score < 0.60` OR `response_type == "clarification"`.

**Auth:** Single `_require_admin` dependency using `APIKeyHeader(name="X-Admin-Key", auto_error=False)`. Reads `ADMIN_SECRET` env var. Returns 401 if missing or mismatch.

**Endpoints to implement:**

1. `GET /api/admin/stats` — Returns `{total_searches, match_count, match_rate, gap_count}`. Use `db.scalar(select(func.count()).select_from(Conversation))` pattern. match_rate = round(match_count / total, 3) if total else 0.0.

2. `GET /api/admin/searches` — Query params: `page: int = 0`, `page_size: int = 25` (25 or 50), `email: str | None = None`, `gap_flag: bool | None = None`, `score_min: float | None = None`, `score_max: float | None = None`, `date_from: str | None = None` (ISO date), `date_to: str | None = None` (ISO date). Returns `{rows: [...], total: int, page: int, page_size: int}`. Each row: `{id, email, query, created_at (ISO str), response_type, match_count, top_match_score, is_gap, gap_resolved}`. Parse `response_experts` JSON (wrap in try/except defaulting to []) to get match_count. `is_gap` = `(top_match_score is not None and top_match_score < GAP_THRESHOLD) or response_type == "clarification"`. Apply filters to SQLAlchemy stmt before limit/offset. For date filters: `datetime.datetime.fromisoformat(date_from)` if provided.

3. `GET /api/admin/gaps` — Returns gap queries aggregated by exact query text: `{gaps: [{id, query, frequency, best_score, resolved}]}`. Frequency = count of conversations with same query text where `is_gap` condition holds. Resolved = True if ALL matching conversations have `gap_resolved=True`. Use SQLAlchemy group_by on `Conversation.query`. Return list ordered by frequency descending. Schema: `select(Conversation.query, func.count(Conversation.id).label("frequency"), func.max(Conversation.top_match_score).label("best_score"), func.min(Conversation.id).label("id")).where((Conversation.top_match_score < GAP_THRESHOLD) | (Conversation.response_type == "clarification")).group_by(Conversation.query).order_by(func.count(Conversation.id).desc())`. For resolved field, use `func.min(Conversation.gap_resolved.cast(Integer))` — resolved=True only if all rows in group are resolved (min of booleans = AND).

4. `POST /api/admin/gaps/{gap_query}/resolve` — Body: `{resolved: bool = True}`. URL-encode the gap_query. Updates `gap_resolved = body.resolved` on all conversations WHERE `query == gap_query`. Use `db.execute(update(Conversation).where(Conversation.query == gap_query).values(gap_resolved=body.resolved))` + `db.commit()`. Use `update` from sqlalchemy. Return `{updated: N}` where N is `result.rowcount`.

5. `GET /api/admin/export/searches.csv` — Query params: same filter params as /searches, plus `filtered: bool = False`. If filtered=False, export all rows ignoring filter params. Generate CSV using `csv.writer` + `io.StringIO`. Metadata header rows first: `["# Export date", date.today().isoformat()]`, `["# Filter applied", "yes" if filtered else "all"]`, `["# Total rows", count]`, `[]` (blank). Column header: `["id", "email", "query", "created_at", "response_type", "match_count", "top_match_score", "is_gap", "gap_resolved"]`. Data rows follow. Filename: `searches-{date.today().isoformat()}.csv`. Return `StreamingResponse(iter([buf.getvalue()]), media_type="text/csv", headers={"Content-Disposition": f"attachment; filename={filename}"})`.

6. `GET /api/admin/export/gaps.csv` — Same approach. Export aggregated gap data (same as /gaps endpoint). Columns: `["query", "frequency", "best_score", "resolved"]`. Filename: `gaps-{date.today().isoformat()}.csv`.

**Imports needed in admin.py:**
```python
import csv
import io
import json
import os
from datetime import date, datetime
from typing import Optional

from fastapi import APIRouter, Depends, HTTPException, Security, status
from fastapi.responses import StreamingResponse
from fastapi.security import APIKeyHeader
from pydantic import BaseModel
from sqlalchemy import Integer, func, select, update
from sqlalchemy.orm import Session

from app.database import get_db
from app.models import Conversation
```

**In app/main.py** — Add admin router import and registration:
- Add `from app.routers import admin` to the existing router imports line
- Add `app.include_router(admin.router)` after `app.include_router(feedback.router)`

Also update the `allow_headers` in CORSMiddleware to include `"X-Admin-Key"`:
```python
allow_headers=["Content-Type", "X-Admin-Key"],
```
This is required so the browser can send the admin key header from the Vercel frontend without a CORS preflight rejection.
  </action>
  <verify>
Start the dev server and test auth rejection:
`cd /Users/sebastianhamers/Documents/TCS && uvicorn app.main:app --port 8001 --reload &`
Wait 3 seconds, then:
`curl -s -o /dev/null -w "%{http_code}" http://localhost:8001/api/admin/stats`
Expected: `401`

Test with key (set ADMIN_SECRET first):
`ADMIN_SECRET=test123 uvicorn app.main:app --port 8001 &`
`curl -s -H "X-Admin-Key: test123" http://localhost:8001/api/admin/stats`
Expected: JSON with `total_searches`, `match_count`, `match_rate`, `gap_count` keys.

Kill the test server after verification: `pkill -f "uvicorn app.main:app --port 8001"`

Also run ruff:
`cd /Users/sebastianhamers/Documents/TCS && python -m ruff check app/routers/admin.py app/models.py app/main.py app/routers/chat.py`
Expected: no errors (or only pre-existing warnings unrelated to new code).
  </verify>
  <done>All 6 /api/admin/* endpoints respond correctly. Unauthenticated requests get 401. Stats endpoint returns correct aggregate shape. Ruff passes on all modified files.</done>
</task>

</tasks>

<verification>
- `python -c "from app.models import Conversation; c = Conversation.__table__.columns; print([col.name for col in c])"` — output includes `top_match_score` and `gap_resolved`
- `python -c "from app.routers import admin; print([r.path for r in admin.router.routes])"` — output includes all 6 admin paths
- `ruff check app/` — no new errors
- curl to /api/admin/stats without key → 401, with correct key → 200 JSON
</verification>

<success_criteria>
- Conversation model has two new nullable columns committed via ALTER TABLE idempotent migration
- chat.py stores top FAISS score on every conversation from this point forward
- All /api/admin/* endpoints require and validate X-Admin-Key header
- Stats, searches, gaps, resolve, and two CSV export endpoints are all registered and functional
- CORS allows X-Admin-Key header from Vercel origin
</success_criteria>

<output>
After completion, create `.planning/phases/07-analytics-dashboard-admin-view-of-searches-expert-matches-gap-tracking-csv-export/07-01-SUMMARY.md`
</output>
